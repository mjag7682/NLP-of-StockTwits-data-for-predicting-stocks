{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "BiLSTM_Fasttext.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-tMNrLt-xG7"
      },
      "source": [
        "#Mount, install and load file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_vGFH0f3cla"
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJk2z0iy3clh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a29150-53a9-43b6-d877-385825a88775"
      },
      "source": [
        "!pip3 install gensim\n",
        "!pip3 install keras\n",
        "!pip3 install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONfGNKaY3clj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f48e25f-17de-4ba1-8d6f-4f755a153847"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pprint\n",
        "import re\n",
        "from lxml import etree\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5df_9w3xZh"
      },
      "source": [
        "# Choose the file to run\n",
        "# https://drive.google.com/file/d/1ZxiH7Oh6iNm7qu338t9BL045eJ4h0xhR/view?usp=sharing\n",
        "# id = '1-1-NxTeGh9HktAvcYMDLuCe0jJK6Cngb'  #Percentage change  Combined_FAANG_percentage_2.2.csv\n",
        "id = '1-4wGVlhCObAoAM_DOLL3D4YsJhOb1ZSj'  #Binary Combined_FAANG_binary_previous.csv\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Combined_FAANG_binary_previous.csv')  \n",
        "train_data = pd.read_csv('Combined_FAANG_binary_previous.csv', sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qGrBaRT3cll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "610021fd-3d39-426d-8e46-bc79c367116b"
      },
      "source": [
        "print(\"Number of training examples {}\".format(len(train_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples 2566858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-9W3iYY_Niw"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik0PYqBY3cln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "43ebbc00-97b1-4026-de44-eb23cd80e617"
      },
      "source": [
        "train_data.drop(train_data[train_data['Date'] <= '2018-07-20'].index, inplace = True)\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>message</th>\n",
              "      <th>datetime</th>\n",
              "      <th>user</th>\n",
              "      <th>message_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl watching gap fill 169 20</td>\n",
              "      <td>2018-11-24 07:02:32</td>\n",
              "      <td>1665234.0</td>\n",
              "      <td>146068732.0</td>\n",
              "      <td>2018-11-24</td>\n",
              "      <td>07:02:32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl</td>\n",
              "      <td>2020-01-27 07:07:03</td>\n",
              "      <td>1229493.0</td>\n",
              "      <td>191978042.0</td>\n",
              "      <td>2020-01-27</td>\n",
              "      <td>07:07:03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl loads cash hand great service business lo...</td>\n",
              "      <td>2018-11-01 23:39:14</td>\n",
              "      <td>123291.0</td>\n",
              "      <td>143688765.0</td>\n",
              "      <td>2018-11-01</td>\n",
              "      <td>23:39:14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>qq became euphoric calls exp week aiming ath f...</td>\n",
              "      <td>2020-05-13 02:13:00</td>\n",
              "      <td>2250451.0</td>\n",
              "      <td>212222428.0</td>\n",
              "      <td>2020-05-13</td>\n",
              "      <td>02:13:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>spy novices like davey day trader lose money s...</td>\n",
              "      <td>2020-06-24 11:12:09</td>\n",
              "      <td>543250.0</td>\n",
              "      <td>222404886.0</td>\n",
              "      <td>2020-06-24</td>\n",
              "      <td>11:12:09</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2566843</th>\n",
              "      <td>NFLX</td>\n",
              "      <td>nflx last 3 months big green candles followed ...</td>\n",
              "      <td>2019-05-01 18:21:25</td>\n",
              "      <td>637003.0</td>\n",
              "      <td>162589986.0</td>\n",
              "      <td>2019-05-01</td>\n",
              "      <td>18:21:25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2566848</th>\n",
              "      <td>NFLX</td>\n",
              "      <td>nflx full move key support</td>\n",
              "      <td>2020-03-12 16:52:43</td>\n",
              "      <td>677915.0</td>\n",
              "      <td>199933357.0</td>\n",
              "      <td>2020-03-12</td>\n",
              "      <td>16:52:43</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2566849</th>\n",
              "      <td>NFLX</td>\n",
              "      <td>spy spx nflx nvda virtually volume today absen...</td>\n",
              "      <td>2019-10-14 18:16:28</td>\n",
              "      <td>55818.0</td>\n",
              "      <td>180328889.0</td>\n",
              "      <td>2019-10-14</td>\n",
              "      <td>18:16:28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2566853</th>\n",
              "      <td>NFLX</td>\n",
              "      <td>nflx sister owns kinda thinking telling sell b...</td>\n",
              "      <td>2019-01-11 20:51:22</td>\n",
              "      <td>607557.0</td>\n",
              "      <td>150426203.0</td>\n",
              "      <td>2019-01-11</td>\n",
              "      <td>20:51:22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2566857</th>\n",
              "      <td>NFLX</td>\n",
              "      <td>nflx stock unstable ups downs like ex girlfriend</td>\n",
              "      <td>2020-02-27 14:52:21</td>\n",
              "      <td>2153160.0</td>\n",
              "      <td>196927202.0</td>\n",
              "      <td>2020-02-27</td>\n",
              "      <td>14:52:21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1021450 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        symbol  ... label\n",
              "1         AAPL  ...     1\n",
              "3         AAPL  ...     0\n",
              "5         AAPL  ...     1\n",
              "8         AAPL  ...     0\n",
              "9         AAPL  ...     0\n",
              "...        ...  ...   ...\n",
              "2566843   NFLX  ...     1\n",
              "2566848   NFLX  ...     0\n",
              "2566849   NFLX  ...     1\n",
              "2566853   NFLX  ...     1\n",
              "2566857   NFLX  ...     0\n",
              "\n",
              "[1021450 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tru24p1m3clp"
      },
      "source": [
        "#Execute to drop Neutral in percentage change labelling\n",
        "# train_data.drop(train_data[train_data['label'] == 0].index, inplace = True)\n",
        "# train_data[\"label\"].replace({-1: 0}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijgr46znlk0Q",
        "outputId": "ed84a93a-124f-44d6-a181-2fa69672ac8e"
      },
      "source": [
        "train_data['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    548894\n",
              "0    472556\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9tZfBMK3clr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "70d1b6ae-b38f-46a6-ddb7-4566190f0530"
      },
      "source": [
        "train_data = train_data.sample(frac=1)\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>message</th>\n",
              "      <th>datetime</th>\n",
              "      <th>user</th>\n",
              "      <th>message_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1864211</th>\n",
              "      <td>GOOGL</td>\n",
              "      <td>spy goog weekly otm options fill 69</td>\n",
              "      <td>2019-06-20 14:50:22</td>\n",
              "      <td>1045552.0</td>\n",
              "      <td>168115763.0</td>\n",
              "      <td>2019-06-20</td>\n",
              "      <td>14:50:22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389246</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl china virus back manufacturing halt soon</td>\n",
              "      <td>2020-06-17 15:30:03</td>\n",
              "      <td>3339933.0</td>\n",
              "      <td>220699728.0</td>\n",
              "      <td>2020-06-17</td>\n",
              "      <td>15:30:03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565670</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>apple unveils new macbook air mac mini ipad pr...</td>\n",
              "      <td>2018-10-30 17:33:04</td>\n",
              "      <td>7108.0</td>\n",
              "      <td>143290974.0</td>\n",
              "      <td>2018-10-30</td>\n",
              "      <td>17:33:04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051006</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl buy done</td>\n",
              "      <td>2018-11-20 14:40:38</td>\n",
              "      <td>1546473.0</td>\n",
              "      <td>145766080.0</td>\n",
              "      <td>2018-11-20</td>\n",
              "      <td>14:40:38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893247</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>amzn aapl everything dropping afterhours</td>\n",
              "      <td>2018-11-26 21:22:14</td>\n",
              "      <td>431459.0</td>\n",
              "      <td>146208883.0</td>\n",
              "      <td>2018-11-26</td>\n",
              "      <td>21:22:14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050799</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>amzn fb googl aapl nflx pox traders</td>\n",
              "      <td>2018-10-30 04:57:24</td>\n",
              "      <td>1511688.0</td>\n",
              "      <td>143213258.0</td>\n",
              "      <td>2018-10-30</td>\n",
              "      <td>04:57:24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353861</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl eps grown impressive 24 97 past year</td>\n",
              "      <td>2019-04-01 02:12:17</td>\n",
              "      <td>47688.0</td>\n",
              "      <td>159038325.0</td>\n",
              "      <td>2019-04-01</td>\n",
              "      <td>02:12:17</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557321</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>spy hey bulls spy 39 even get 50 returns aapl ...</td>\n",
              "      <td>2019-04-03 15:11:54</td>\n",
              "      <td>836502.0</td>\n",
              "      <td>159385061.0</td>\n",
              "      <td>2019-04-03</td>\n",
              "      <td>15:11:54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832333</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl nvda fb highs</td>\n",
              "      <td>2018-12-17 15:12:53</td>\n",
              "      <td>397769.0</td>\n",
              "      <td>148115565.0</td>\n",
              "      <td>2018-12-17</td>\n",
              "      <td>15:12:53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002275</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl garbage garbage cnbc said would outperform</td>\n",
              "      <td>2018-11-30 19:15:34</td>\n",
              "      <td>1514704.0</td>\n",
              "      <td>146675362.0</td>\n",
              "      <td>2018-11-30</td>\n",
              "      <td>19:15:34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1021450 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        symbol  ... label\n",
              "1864211  GOOGL  ...     1\n",
              "389246    AAPL  ...     0\n",
              "565670    AAPL  ...     1\n",
              "1051006   AAPL  ...     0\n",
              "893247    AAPL  ...     1\n",
              "...        ...  ...   ...\n",
              "1050799   AAPL  ...     1\n",
              "353861    AAPL  ...     1\n",
              "557321    AAPL  ...     1\n",
              "832333    AAPL  ...     0\n",
              "1002275   AAPL  ...     0\n",
              "\n",
              "[1021450 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMdpvq743clt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "a7f66d7a-1d86-4697-930b-6d4a55f1bad7"
      },
      "source": [
        "# Drop the NA values\n",
        "train_data = train_data.dropna(subset=['message']).reset_index()  \n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>symbol</th>\n",
              "      <th>message</th>\n",
              "      <th>datetime</th>\n",
              "      <th>user</th>\n",
              "      <th>message_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1864211</td>\n",
              "      <td>GOOGL</td>\n",
              "      <td>spy goog weekly otm options fill 69</td>\n",
              "      <td>2019-06-20 14:50:22</td>\n",
              "      <td>1045552.0</td>\n",
              "      <td>168115763.0</td>\n",
              "      <td>2019-06-20</td>\n",
              "      <td>14:50:22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>389246</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl china virus back manufacturing halt soon</td>\n",
              "      <td>2020-06-17 15:30:03</td>\n",
              "      <td>3339933.0</td>\n",
              "      <td>220699728.0</td>\n",
              "      <td>2020-06-17</td>\n",
              "      <td>15:30:03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>565670</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>apple unveils new macbook air mac mini ipad pr...</td>\n",
              "      <td>2018-10-30 17:33:04</td>\n",
              "      <td>7108.0</td>\n",
              "      <td>143290974.0</td>\n",
              "      <td>2018-10-30</td>\n",
              "      <td>17:33:04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1051006</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl buy done</td>\n",
              "      <td>2018-11-20 14:40:38</td>\n",
              "      <td>1546473.0</td>\n",
              "      <td>145766080.0</td>\n",
              "      <td>2018-11-20</td>\n",
              "      <td>14:40:38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>893247</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>amzn aapl everything dropping afterhours</td>\n",
              "      <td>2018-11-26 21:22:14</td>\n",
              "      <td>431459.0</td>\n",
              "      <td>146208883.0</td>\n",
              "      <td>2018-11-26</td>\n",
              "      <td>21:22:14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021445</th>\n",
              "      <td>1050799</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>amzn fb googl aapl nflx pox traders</td>\n",
              "      <td>2018-10-30 04:57:24</td>\n",
              "      <td>1511688.0</td>\n",
              "      <td>143213258.0</td>\n",
              "      <td>2018-10-30</td>\n",
              "      <td>04:57:24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021446</th>\n",
              "      <td>353861</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl eps grown impressive 24 97 past year</td>\n",
              "      <td>2019-04-01 02:12:17</td>\n",
              "      <td>47688.0</td>\n",
              "      <td>159038325.0</td>\n",
              "      <td>2019-04-01</td>\n",
              "      <td>02:12:17</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021447</th>\n",
              "      <td>557321</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>spy hey bulls spy 39 even get 50 returns aapl ...</td>\n",
              "      <td>2019-04-03 15:11:54</td>\n",
              "      <td>836502.0</td>\n",
              "      <td>159385061.0</td>\n",
              "      <td>2019-04-03</td>\n",
              "      <td>15:11:54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021448</th>\n",
              "      <td>832333</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl nvda fb highs</td>\n",
              "      <td>2018-12-17 15:12:53</td>\n",
              "      <td>397769.0</td>\n",
              "      <td>148115565.0</td>\n",
              "      <td>2018-12-17</td>\n",
              "      <td>15:12:53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021449</th>\n",
              "      <td>1002275</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl garbage garbage cnbc said would outperform</td>\n",
              "      <td>2018-11-30 19:15:34</td>\n",
              "      <td>1514704.0</td>\n",
              "      <td>146675362.0</td>\n",
              "      <td>2018-11-30</td>\n",
              "      <td>19:15:34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1021450 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           index symbol  ...      Time label\n",
              "0        1864211  GOOGL  ...  14:50:22     1\n",
              "1         389246   AAPL  ...  15:30:03     0\n",
              "2         565670   AAPL  ...  17:33:04     1\n",
              "3        1051006   AAPL  ...  14:40:38     0\n",
              "4         893247   AAPL  ...  21:22:14     1\n",
              "...          ...    ...  ...       ...   ...\n",
              "1021445  1050799   AAPL  ...  04:57:24     1\n",
              "1021446   353861   AAPL  ...  02:12:17     1\n",
              "1021447   557321   AAPL  ...  15:11:54     1\n",
              "1021448   832333   AAPL  ...  15:12:53     0\n",
              "1021449  1002275   AAPL  ...  19:15:34     0\n",
              "\n",
              "[1021450 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQL5r87b3clw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fce969f-9d6c-47e4-ba0b-d333982d5a87"
      },
      "source": [
        "# Tokenization\n",
        "target_text = train_data['message'].values\n",
        "sentences=[]\n",
        "sentences=[word_tokenize(sentence) for sentence in target_text]\n",
        "\n",
        "# Prints only 10 (tokenised) sentences\n",
        "print(sentences[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['spy', 'goog', 'weekly', 'otm', 'options', 'fill', '69'], ['aapl', 'china', 'virus', 'back', 'manufacturing', 'halt', 'soon'], ['apple', 'unveils', 'new', 'macbook', 'air', 'mac', 'mini', 'ipad', 'pro', '39', 'need', 'know', 'aapl'], ['aapl', 'buy', 'done'], ['amzn', 'aapl', 'everything', 'dropping', 'afterhours'], ['amzn', 'swing', 'higher', 'still', 'time', 'buy'], ['aapl', 'good', 'nrws', 'markets', 'peak', 'deaths', 'day', 'virus', 'control', 'stimulus'], ['aapl', 'hey', 'look', 'two', 'five', 'year', 'charts', 'bb', 'seeing', 'I', 'seeing'], ['ibio', 'canceled', 'nflx', 'subscription', 'entertainment', 'comes', 'board'], ['aapl', 'say', 'wait', 'r', 'get', 'ar', 'like', 'xs', 'new', 'game', 'playing', 'future', 'developers', 'like', 'atvi']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UF_t0Wg_lRx"
      },
      "source": [
        "# FastText implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H16ThMPR3cly"
      },
      "source": [
        "from gensim.models import FastText\n",
        "ft_sg_model = FastText(sentences, size=100, window=5, min_count=5, workers=4, sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErtjEYRg6HNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3582288b-8e12-4c02-c760-450ee858763b"
      },
      "source": [
        "similar_words=ft_sg_model.wv.most_similar(\"aapl\")\n",
        "pprint.pprint(similar_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('aapll', 0.8026167154312134),\n",
            " ('mflx', 0.7674264907836914),\n",
            " ('appl', 0.7521910071372986),\n",
            " ('fb', 0.7379411458969116),\n",
            " ('nflx', 0.7165732383728027),\n",
            " ('spy', 0.7053292989730835),\n",
            " ('craapl', 0.7022196054458618),\n",
            " ('spyy', 0.6937599182128906),\n",
            " ('amzn', 0.6766653060913086),\n",
            " ('smzn', 0.6752709150314331)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opXSd6rM_xpc"
      },
      "source": [
        "Splitting data into 90:10 ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQpR-zuj3cl8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_data['message'].values, train_data['label'].values, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf6qL9e23cl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2767076a-1d10-4810-a093-5195590c10c9"
      },
      "source": [
        "df_train = pd.DataFrame(y_train,columns=['label'])\n",
        "df_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    494148\n",
              "0    425157\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USanarOs3cmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397ac3e5-5588-4272-bf9f-ab3716a876a3"
      },
      "source": [
        "df_test = pd.DataFrame(y_test,columns=['label'])\n",
        "df_test['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    54746\n",
              "0    47399\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o31hsdTb3cmB"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from string import punctuation\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer, InputSpec\n",
        "from keras import initializers\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYGuNGkM3cmD"
      },
      "source": [
        "# Hyperparameters\n",
        "MAX_SEQUENCE_LENGTH = 160\n",
        "MAX_NB_WORDS = 200000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrprGvd93cmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4a0df3-a7f2-44f5-9c26-d83659bcd31e"
      },
      "source": [
        "# Data conversion into train and validation set\n",
        "from keras.utils.np_utils import to_categorical\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "sequences_1 = tokenizer.texts_to_sequences(X_train)\n",
        "# sequences_1 = tokenizer.texts_to_sequences(train_data['message'].values)\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens' % len(word_index))\n",
        "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "# data_2 = pad_sequences(sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels = to_categorical(np.asarray(y_train))\n",
        "# labels = to_categorical(np.asarray(train_data['label'].values))\n",
        "labels_test = to_categorical(np.asarray(y_test))\n",
        "print('Shape of data tensor:', data_1.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "indices = np.arange(data_1.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data_1[indices]\n",
        "labels = labels[indices]\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = data[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 104433 unique tokens\n",
            "Shape of data tensor: (919305, 160)\n",
            "Shape of label tensor: (919305, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEiZjTyS3cmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf916bc-4a9a-4e06-a3b3-4e81fb95390d"
      },
      "source": [
        "print('Traing and validation set number of positive and negative reviews')\n",
        "print(y_train.sum(axis=0))\n",
        "print(y_val.sum(axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traing and validation set number of positive and negative reviews\n",
            "[382674. 444701.]\n",
            "[42483. 49447.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9xFcX4zAIeE"
      },
      "source": [
        "##Embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKfO0BNl3cmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9fa2a5d-df0c-41e7-fc6e-dc78528e0504"
      },
      "source": [
        "print('Preparing embedding matrix')\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
        "\n",
        "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if word in ft_sg_model.wv.vocab:\n",
        "        embedding_matrix[i] = ft_sg_model.wv.word_vec(word)\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing embedding matrix\n",
            "Null word embeddings: 70088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjaCPsWuAM20"
      },
      "source": [
        "## Model Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25L0xloR3cmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a982e626-b693-4f06-ae64-54a5df6ad08a"
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True)\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n",
        "preds = Dense(2, activation='softmax')(l_lstm)\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(\"model fitting - Bidirectional LSTM\")\n",
        "model.summary()\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "          epochs=2, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model fitting - Bidirectional LSTM\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 160)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 160, 100)          10443400  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 10,604,602\n",
            "Trainable params: 10,604,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "25856/25856 [==============================] - 7573s 293ms/step - loss: 0.6830 - acc: 0.5588 - val_loss: 0.6818 - val_acc: 0.5597\n",
            "Epoch 2/2\n",
            "25856/25856 [==============================] - 7726s 299ms/step - loss: 0.6765 - acc: 0.5772 - val_loss: 0.6804 - val_acc: 0.5713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f07416b3fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu4fndbRAYWJ"
      },
      "source": [
        "##Attention layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIhCDxGZ3cmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173808ac-5f78-4d84-80c0-480a45723e87"
      },
      "source": [
        "# Attention GRU network\t\t  \n",
        "class AttLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.init = initializers.get('normal')\n",
        "        #self.input_spec = [InputSpec(ndim=3)]\n",
        "        super(AttLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape)==3\n",
        "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\") \n",
        "        super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
        "        at=K.softmax(et)\n",
        "        at=K.expand_dims(at,axis=-1)\n",
        "        output=x*at\n",
        "        return K.sum(output,axis=1)\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True)\n",
        "\n",
        "\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "l_gru = Bidirectional(GRU(100, return_sequences=True))(embedded_sequences)\n",
        "l_att = AttLayer()(l_gru)\n",
        "preds = Dense(2, activation='softmax')(l_att)\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(\"model fitting - attention GRU network\")\n",
        "model.summary()\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "          epochs=2, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model fitting - attention GRU network\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 160)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 160, 100)          10443400  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 160, 200)          121200    \n",
            "_________________________________________________________________\n",
            "att_layer (AttLayer)         (None, 200)               360       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 10,565,362\n",
            "Trainable params: 10,565,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "25856/25856 [==============================] - 7474s 289ms/step - loss: 0.6828 - acc: 0.5592 - val_loss: 0.6797 - val_acc: 0.5682\n",
            "Epoch 2/2\n",
            "25856/25856 [==============================] - 7531s 291ms/step - loss: 0.6756 - acc: 0.5765 - val_loss: 0.6812 - val_acc: 0.5699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f073d89c828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3U0zqyFAisn"
      },
      "source": [
        "##Prediction and Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzTcB-IX3cmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e7631e-eb3e-4e1c-e064-e20a06d87e08"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print('Start making the submission before fine-tuning')\n",
        "\n",
        "preds = model.predict(data_test, batch_size=32, verbose=1)\n",
        "pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "print(pred_flat)\n",
        "print(classification_report(y_test, pred_flat))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start making the submission before fine-tuning\n",
            "3193/3193 [==============================] - 178s 56ms/step\n",
            "[1 0 1 ... 1 1 1]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.32      0.41     47399\n",
            "           1       0.57      0.78      0.66     54746\n",
            "\n",
            "    accuracy                           0.57    102145\n",
            "   macro avg       0.57      0.55      0.54    102145\n",
            "weighted avg       0.57      0.57      0.54    102145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}