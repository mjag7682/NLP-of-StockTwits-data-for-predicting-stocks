{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Labelling_Approach2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjag7682/CS9-1-NLP-for-Twitter-Data-for-predicting-stocks/blob/labelling_approaches/Labelling_Approach2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkqDSyOVDpRD"
      },
      "source": [
        "## Install, Import, Mount statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gXtdFlzndWh",
        "outputId": "82ea50fa-6336-4833-e86a-16f97f922e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "!pip install contractions\n",
        "!pip install emoji\n",
        "!pip install ekphrasis\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "import nltk\n",
        "import contractions\n",
        "import torch\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import TweetTokenizer \n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "import requests \n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from tensorflow import keras\n",
        "# import bert\n",
        "# from bert import run_classifier\n",
        "# from bert import optimization\n",
        "# from bert import tokenization\n",
        "import os\n",
        "import pprint\n",
        "import json\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "from ekphrasis.classes.segmenter import Segmenter\n",
        "import itertools\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: ekphrasis in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (5.8)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (1.1.0)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (4.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (3.2.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (0.4.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (1.18.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (3.2.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->ekphrasis) (0.2.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->ekphrasis) (1.15.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSZ7lIUN3ofk",
        "outputId": "63151a4f-c3a9-4e66-b719-9814c53608a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFOsh5pJq2QZ"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "#load csv file\n",
        "#stocktwits_PG\n",
        "#1tlueLaJhlduNMgRHk8Omkog5nNI8I8Yk\n",
        "# id = '1diLooyj8DtyyxwiihpbTJdfY4D98irLE'  #AAPL\n",
        "# id = '1tlueLaJhlduNMgRHk8Omkog5nNI8I8Yk'  #PG\n",
        "# downloaded = drive.CreateFile({'id':id}) \n",
        "# downloaded.GetContentFile('stocktwits_PG.csv')\n",
        "# df_st1 = pd.read_csv('stocktwits_PG.csv')\n",
        "# df_st1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opcbq6SN7HY_"
      },
      "source": [
        "def get_compData(comp):\n",
        "  if comp =='AAPL':\n",
        "    # AAPL: https://drive.google.com/file/d/1diLooyj8DtyyxwiihpbTJdfY4D98irLE/view?usp=sharing\n",
        "    id = '1diLooyj8DtyyxwiihpbTJdfY4D98irLE'\n",
        "    downloaded1 = drive.CreateFile({'id':id}) \n",
        "    downloaded1.GetContentFile('stocktwits_AAPL.csv')\n",
        "    df_st1 = pd.read_csv('stocktwits_AAPL.csv')\n",
        "    return df_st1\n",
        "  elif comp=='ADBE':\n",
        "    # ADBE: https://drive.google.com/file/d/1SMyRg8aUnnQTbukVadBo814qdS6xDnP1/view?usp=sharing\n",
        "    id = '1SMyRg8aUnnQTbukVadBo814qdS6xDnP1'\n",
        "    downloaded2 = drive.CreateFile({'id':id}) \n",
        "    downloaded2.GetContentFile('stocktwits_ADBE.csv')\n",
        "    df_st2 = pd.read_csv('stocktwits_ADBE.csv')\n",
        "    return df_st2\n",
        "  elif comp=='AMZN':\n",
        "    # AMZN: https://drive.google.com/file/d/1ffmFOrlcaTCCByKMq7E1LCXXK6daMkB_/view?usp=sharing\n",
        "    id = '1ffmFOrlcaTCCByKMq7E1LCXXK6daMkB_'\n",
        "    downloaded3 = drive.CreateFile({'id':id}) \n",
        "    downloaded3.GetContentFile('stocktwits_AMZN.csv')\n",
        "    df_st3 = pd.read_csv('stocktwits_AMZN.csv')\n",
        "    return df_st3\n",
        "  elif comp=='BAC':\n",
        "    # BAC: https://drive.google.com/file/d/1HeaKJtlSz2xiLT3sx5FLdYmzCkVDGIjW/view?usp=sharing\n",
        "    id = '1HeaKJtlSz2xiLT3sx5FLdYmzCkVDGIjW'\n",
        "    downloaded4 = drive.CreateFile({'id':id}) \n",
        "    downloaded4.GetContentFile('stocktwits_BAC.csv')\n",
        "    df_st4 = pd.read_csv('stocktwits_BAC.csv')\n",
        "    return df_st4\n",
        "\n",
        "  elif comp=='BRK.A':\n",
        "\n",
        "    #BRK_A: https://drive.google.com/file/d/1HeQhAU20YyT1tRCD-yN83vrUGY7jDDSt/view?usp=sharing\n",
        "    id = '1HeQhAU20YyT1tRCD-yN83vrUGY7jDDSt'\n",
        "    downloaded5 = drive.CreateFile({'id':id}) \n",
        "    downloaded5.GetContentFile('stocktwits_BRK_A.csv')\n",
        "    df_st5 = pd.read_csv('stocktwits_BRK_A.csv')\n",
        "    return df_st5\n",
        "  elif comp=='BRK.B':\n",
        "    #BRK_B: https://drive.google.com/file/d/1FRrwrIVJVyFqg025SWasKW84qOJMhe84/view?usp=sharing\n",
        "    id = '1FRrwrIVJVyFqg025SWasKW84qOJMhe84'\n",
        "    downloaded6 = drive.CreateFile({'id':id}) \n",
        "    downloaded6.GetContentFile('stocktwits_BRK_B.csv')\n",
        "    df_st6 = pd.read_csv('stocktwits_BRK_B.csv')\n",
        "    return df_st6\n",
        "  elif comp=='DIA':\n",
        "    #DIA: https://drive.google.com/file/d/1riZ8IdkupLre9NQ7McBO21wDFVX_NPvg/view?usp=sharing\n",
        "    id = '1riZ8IdkupLre9NQ7McBO21wDFVX_NPvg'\n",
        "    downloaded7 = drive.CreateFile({'id':id}) \n",
        "    downloaded7.GetContentFile('stocktwits_DIA.csv')\n",
        "    df_st7 = pd.read_csv('stocktwits_DIA.csv')\n",
        "    return df_st7\n",
        "  elif comp=='DIS':\n",
        "    #DIS: https://drive.google.com/file/d/1y5IT3gA_yIJnFLTsxy1GHdIY4SHwj84Y/view?usp=sharing\n",
        "    id = '1y5IT3gA_yIJnFLTsxy1GHdIY4SHwj84Y'\n",
        "    downloaded8 = drive.CreateFile({'id':id}) \n",
        "    downloaded8.GetContentFile('stocktwits_DIS.csv')\n",
        "    df_st8 = pd.read_csv('stocktwits_DIS.csv')\n",
        "    return df_st8\n",
        "  elif comp=='FB':\n",
        "    #FB: https://drive.google.com/file/d/1x1FugJhUQx9xKWS9LYnio1MU8oi5iuTc/view?usp=sharing\n",
        "    id = '1x1FugJhUQx9xKWS9LYnio1MU8oi5iuTc'\n",
        "    downloaded9 = drive.CreateFile({'id':id}) \n",
        "    downloaded9.GetContentFile('stocktwits_FB.csv')\n",
        "    df_st9 = pd.read_csv('stocktwits_FB.csv')\n",
        "    return df_st9\n",
        "  elif comp=='GOOG':\n",
        "    #GOOG: https://drive.google.com/file/d/1UMnPXfG_XkgLJAQ2VtLvMPBPZhN68Ezw/view?usp=sharing\n",
        "    id = '1UMnPXfG_XkgLJAQ2VtLvMPBPZhN68Ezw'\n",
        "    downloaded10 = drive.CreateFile({'id':id}) \n",
        "    downloaded10.GetContentFile('stocktwits_GOOG.csv')\n",
        "    df_st10 = pd.read_csv('stocktwits_GOOG.csv')\n",
        "    return df_st10\n",
        "  elif comp=='GOOGL':\n",
        "    #GOOGL: https://drive.google.com/file/d/1NbCpQX0sTgXsqcW7xMbkrDPlAOscIoTL/view?usp=sharing\n",
        "    id = '1NbCpQX0sTgXsqcW7xMbkrDPlAOscIoTL'\n",
        "    downloaded11 = drive.CreateFile({'id':id}) \n",
        "    downloaded11.GetContentFile('stocktwits_GOOGL.csv')\n",
        "    df_st11 = pd.read_csv('stocktwits_GOOGL.csv')\n",
        "    return df_st11\n",
        "  elif comp=='HD':\n",
        "    #HD: https://drive.google.com/file/d/10wbCzJMcjLWAqrlEtHlWieIrq7dyolG2/view?usp=sharing\n",
        "    id = '10wbCzJMcjLWAqrlEtHlWieIrq7dyolG2'\n",
        "    downloaded12 = drive.CreateFile({'id':id}) \n",
        "    downloaded12.GetContentFile('stocktwits_HD.csv')\n",
        "    df_st12 = pd.read_csv('stocktwits_HD.csv')\n",
        "    return df_st12\n",
        "  elif comp=='INTC':\n",
        "    # INTC: https://drive.google.com/file/d/1k1-NSl8qLTa2oDs1G8CFC4CJzkv9mugw/view?usp=sharing \n",
        "    id = '1k1-NSl8qLTa2oDs1G8CFC4CJzkv9mugw'\n",
        "    downloaded13 = drive.CreateFile({'id':id}) \n",
        "    downloaded13.GetContentFile('stocktwits_INTC.csv')\n",
        "    df_st13 = pd.read_csv('stocktwits_INTC.csv')\n",
        "    return df_st13\n",
        "  elif comp=='JNJ':\n",
        "    # JNJ: https://drive.google.com/file/d/1Qiwu9vbDYU527szR8waaFDoFCyY4i_bc/view?usp=sharing\n",
        "    id = '1Qiwu9vbDYU527szR8waaFDoFCyY4i_bc'\n",
        "    downloaded14 = drive.CreateFile({'id':id}) \n",
        "    downloaded14.GetContentFile('stocktwits_JNJ.csv')\n",
        "    df_st14 = pd.read_csv('stocktwits_JNJ.csv')\n",
        "    return df_st14\n",
        "  elif comp=='NFLX':\n",
        "    # NFLX: https://drive.google.com/file/d/1DdJ8MPdgt9bxF3ZagkWUp45N4RMQ8Al6/view?usp=sharing\n",
        "    id = '1DdJ8MPdgt9bxF3ZagkWUp45N4RMQ8Al6'\n",
        "    downloaded15 = drive.CreateFile({'id':id}) \n",
        "    downloaded15.GetContentFile('stocktwits_NFLX.csv')\n",
        "    df_st15 = pd.read_csv('stocktwits_NFLX.csv')\n",
        "    return df_st15\n",
        "  elif comp=='PG':\n",
        "    # PG: https://drive.google.com/file/d/1tlueLaJhlduNMgRHk8Omkog5nNI8I8Yk/view?usp=sharing\n",
        "    id = '1tlueLaJhlduNMgRHk8Omkog5nNI8I8Yk'\n",
        "    downloaded16 = drive.CreateFile({'id':id}) \n",
        "    downloaded16.GetContentFile('stocktwits_PG.csv')\n",
        "    df_st16 = pd.read_csv('stocktwits_PG.csv')\n",
        "    return df_st16\n",
        "  elif comp=='QQQ':\n",
        "    # QQQ: https://drive.google.com/file/d/1gUsl5L4VBgsL9oqBxaUdk6tA9r4VxDjo/view?usp=sharing\n",
        "    id = '1gUsl5L4VBgsL9oqBxaUdk6tA9r4VxDjo'\n",
        "    downloaded17 = drive.CreateFile({'id':id}) \n",
        "    downloaded17.GetContentFile('stocktwits_QQQ.csv')\n",
        "    df_st17 = pd.read_csv('stocktwits_QQQ.csv')\n",
        "    return df_st17\n",
        "  elif comp=='SPY':\n",
        "    # SPY: https://drive.google.com/file/d/10s-zYQPIqlkNsUahgzDRqJGw0VAkn-R1/view?usp=sharing\n",
        "    id = '10s-zYQPIqlkNsUahgzDRqJGw0VAkn-R1'\n",
        "    downloaded18 = drive.CreateFile({'id':id}) \n",
        "    downloaded18.GetContentFile('stocktwits_SPY.csv')\n",
        "    df_st18 = pd.read_csv('stocktwits_SPY.csv')\n",
        "    return df_st18\n",
        "  elif comp=='T':\n",
        "    # T: https://drive.google.com/file/d/1rk3PsikhgrA7MxV28tUbzj7EOn9K5Ixu/view?usp=sharing\n",
        "    id = '1rk3PsikhgrA7MxV28tUbzj7EOn9K5Ixu'\n",
        "    downloaded19 = drive.CreateFile({'id':id}) \n",
        "    downloaded19.GetContentFile('stocktwits_T.csv')\n",
        "    df_st19 = pd.read_csv('stocktwits_T.csv')\n",
        "    return df_st19\n",
        "  elif comp=='TSLA':\n",
        "    # TSLA: https://drive.google.com/file/d/1on57uk2gd_CLsnj1dcRfuB_KsYydzEp2/view?usp=sharing\n",
        "    id = '1on57uk2gd_CLsnj1dcRfuB_KsYydzEp2'\n",
        "    downloaded20 = drive.CreateFile({'id':id}) \n",
        "    downloaded20.GetContentFile('stocktwits_TSLA.csv')\n",
        "    df_st20 = pd.read_csv('stocktwits_TSLA.csv')\n",
        "    return df_st20\n",
        "  elif comp=='UNH':\n",
        "    # UNH: https://drive.google.com/file/d/1zguMHb3pL2tCT4TYV8XJcP-dWTcq28mY/view?usp=sharing\n",
        "    id = '1zguMHb3pL2tCT4TYV8XJcP-dWTcq28mY'\n",
        "    downloaded21 = drive.CreateFile({'id':id}) \n",
        "    downloaded21.GetContentFile('stocktwits_UNH.csv')\n",
        "    df_st21 = pd.read_csv('stocktwits_UNH.csv')\n",
        "    return df_st21\n",
        "  elif comp=='V':\n",
        "    # V: https://drive.google.com/file/d/1qLI1Rsyf2ebZu53I8QaFuOQSeTyZShLg/view?usp=sharing\n",
        "    id = '1qLI1Rsyf2ebZu53I8QaFuOQSeTyZShLg'\n",
        "    downloaded22 = drive.CreateFile({'id':id}) \n",
        "    downloaded22.GetContentFile('stocktwits_V.csv')\n",
        "    df_st22 = pd.read_csv('stocktwits_V.csv')\n",
        "    return df_st22\n",
        "  elif comp=='VIX':\n",
        "    # VIX: https://drive.google.com/file/d/1SoIue0nfsn_GGMOroFg3tEp8re-v7PnJ/view?usp=sharing\n",
        "    id = '1SoIue0nfsn_GGMOroFg3tEp8re-v7PnJ'\n",
        "    downloaded23 = drive.CreateFile({'id':id}) \n",
        "    downloaded23.GetContentFile('stocktwits_VIX.csv')\n",
        "    df_st23 = pd.read_csv('stocktwits_VIX.csv')\n",
        "    return df_st23\n",
        "  elif comp=='VZ':\n",
        "    # VZ: https://drive.google.com/file/d/1ddISbB0qfDpM69senqEmmf6xbNWOpNUJ/view?usp=sharing\n",
        "    id = '1ddISbB0qfDpM69senqEmmf6xbNWOpNUJ'\n",
        "    downloaded24 = drive.CreateFile({'id':id}) \n",
        "    downloaded24.GetContentFile('stocktwits_VZ.csv')\n",
        "    df_st24 = pd.read_csv('stocktwits_VZ.csv')\n",
        "    return df_st24\n",
        "  elif comp=='WMT':\n",
        "    # WMT: https://drive.google.com/file/d/14Zdh1ZCj5RxZltXknG3Qisxhwzge5rkV/view?usp=sharing\n",
        "    id = '14Zdh1ZCj5RxZltXknG3Qisxhwzge5rkV'\n",
        "    downloaded25 = drive.CreateFile({'id':id}) \n",
        "    downloaded25.GetContentFile('stocktwits_WMT.csv')\n",
        "    df_st25 = pd.read_csv('stocktwits_WMT.csv')\n",
        "    return df_st25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GSEYpSN22v-"
      },
      "source": [
        "#Change the company name here\n",
        "df_st1 = get_compData('PG')\n",
        "#change the directory you want to save the file\n",
        "PATH='/content/drive/My Drive/sentiment_data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8KjCLPk5DK-",
        "outputId": "81d7fedb-972b-4a20-be15-2591dd5c61a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df_st1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>message</th>\n",
              "      <th>datetime</th>\n",
              "      <th>user</th>\n",
              "      <th>message_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PG</td>\n",
              "      <td>TOP DOW 30 Stocks with the highest Payout Rati...</td>\n",
              "      <td>2020-07-21T21:37:30Z</td>\n",
              "      <td>1550174</td>\n",
              "      <td>229729267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PG</td>\n",
              "      <td>$PG Green to red move:   1.11 percentage  to -...</td>\n",
              "      <td>2020-07-21T20:28:32Z</td>\n",
              "      <td>1442893</td>\n",
              "      <td>229707089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PG</td>\n",
              "      <td>$PG Bought.  Hopefully, Ol&amp;#39; Gil made the r...</td>\n",
              "      <td>2020-07-21T19:49:53Z</td>\n",
              "      <td>2926317</td>\n",
              "      <td>229689416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PG</td>\n",
              "      <td>$PG 322 overnight open 321 then down 319</td>\n",
              "      <td>2020-07-21T19:42:24Z</td>\n",
              "      <td>308683</td>\n",
              "      <td>229686076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PG</td>\n",
              "      <td>$PG Market share grabs continue for Procter &amp;a...</td>\n",
              "      <td>2020-07-21T19:31:05Z</td>\n",
              "      <td>2762379</td>\n",
              "      <td>229680970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  symbol  ... message_id\n",
              "0     PG  ...  229729267\n",
              "1     PG  ...  229707089\n",
              "2     PG  ...  229689416\n",
              "3     PG  ...  229686076\n",
              "4     PG  ...  229680970\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1O0ewkADyRM"
      },
      "source": [
        "## Load file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVXGLwXaq5I5"
      },
      "source": [
        "# df_comb = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Capstone/Labelled (Percentage change)/WMT_label2.1.csv')\n",
        "# combine_ds = df_comb.sample(frac=1)\n",
        "# combine_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8G7WU8SD08e"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z70r1eYrnoB_",
        "outputId": "696003d5-4429-476c-a10e-055188dff652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "df_st1['message'] = df_st1['message'].str.lower()\n",
        "message = df_st1['message'].tolist()\n",
        "\n",
        "print(message[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['top dow 30 stocks with the highest payout ratio: $cvx $pg $ba $xom $ko\\nhttps://www.finscreener.com/screener/best-dividend-stocks/dj30?&amp;o=1013', '$pg green to red move:   1.11 percentage  to --0.14 percentage  https://www.sleekoptions.com/sleekscan.aspx?did=pg', '$pg bought.  hopefully, ol&#39; gil made the right decision.', '$pg 322 overnight open 321 then down 319', '$pg market share grabs continue for procter &amp; gamble and clorox \\n\\nhttps://newsfilter.io/a/fc14c65209137f2f70daa24bd9520fa7', '$pg  tough times never last, but tough people do.', 'midday:  $mdlz  $pg  $blk   are our stock suggestions for selling short. more information about sell price range, charts, expected sell returns and option prices are given in our midday video (7/21/2020), only on justrading youtube channel, check it out.  if you would like our daily suggested stocks report, you can join us on patreon as collaborator, supporter or winner. thank you! (part 2)', '$gnus some boards are littered with the worst kinds of people. beggars, thieves, prostitutes (i&#39;m looking at you $pg). but not $gnus. this community is comprised of true ladies and gentlemen -- who want nothing but the best for their fellow man. it&#39;s an honor to serve alongside you fine people.', 'premier reports q2 production results and mercedes restart update http://www.conferencecalltranscripts.org/include?location=https://newswire.ca/news-releases/premier-reports-q2-production-results-and-mercedes-restart-update-879617603.html $pg', 'peak profit for the last 6 expired option alerts for $pg 414.63  | 3.82  | 22.05  | 100.89  | -97.27  | 34.38  |']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C65MA9lJnwEv"
      },
      "source": [
        "def remove_stopwords(msg):\n",
        "    filtered_sentence = [w for w in msg_tokens if not w in stop_words]\n",
        "    return filtered_sentence\n",
        "\n",
        "def remove_punctuation_re(x):\n",
        "    x = ' '.join(re.sub(\"https?://\\S+\",\"\",x).split())     #Removing URLs\n",
        "\n",
        "    x = ' '.join(re.sub(\"^@\\S+|\\s@\\S+\",\"\",x).split())     #Removing Mentions\n",
        "\n",
        "    # x = ' '.join(re.sub(r'[^$\\w\\s]',\" \",x).split())\n",
        "    x = ' '.join(re.sub(r'[^\\w\\s]',\" \",x).split())        #Removes Hashtags\n",
        "\n",
        "    x = ' '.join(re.sub(r'_',\" \",x).split())              #Removing _ from emojis text\n",
        "\n",
        "    return x\n",
        "\n",
        "# replace repeating letter\n",
        "def rpt_replace(match):\n",
        "    # print(match.group(1))\n",
        "    return match.group(1)+match.group(1)\n",
        "\n",
        "# substitute original word with replaced word, if any\n",
        "def processRepeatings(data):\n",
        "    re_t= re.sub(message_rpt, rpt_replace, data )\n",
        "    # print(re_t)\n",
        "    return re_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3YWRwzLBGs1",
        "outputId": "2394378a-3e31-4aba-925b-c6df5ba998fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "stop_words = sw.words(\"english\")\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "detokenizer = TreebankWordDetokenizer()\n",
        "# message_p = []\n",
        "\n",
        "# for repeating characters in words\n",
        "message_rpt = re.compile(r\"(.)\\1{2,}\", re.IGNORECASE)\n",
        "\n",
        "# segmenter using the word statistics from Twitter\n",
        "seg_tw = Segmenter(corpus=\"twitter\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LRFAxgcn_fi"
      },
      "source": [
        "message_p = []\n",
        "for msg in message:\n",
        "    # remove emojis\n",
        "    msg = emoji.demojize(msg)\n",
        "\n",
        "    # fix contractions\n",
        "    msg = contractions.fix(msg)\n",
        "\n",
        "    # remove punctuations\n",
        "    msg = remove_punctuation_re(msg) \n",
        "\n",
        "    #tokenize\n",
        "    msg_tokens = tweet_tokenizer.tokenize(msg)\n",
        "\n",
        "    #For Hashtags elongated words using Word segmenter\n",
        "    message_seg = []\n",
        "    for w in msg_tokens:\n",
        "      message_seg.append(seg_tw.segment(w))\n",
        "\n",
        "    # remove stopwords\n",
        "    msg = remove_stopwords(message_seg)\n",
        "\n",
        "    if 'rt' in msg:\n",
        "      # remove retweets\n",
        "      message_p.append('-1')\n",
        "    else: \n",
        "      # detokenize\n",
        "      msg = detokenizer.detokenize(msg)\n",
        "\n",
        "      # removing repeating characters like hurrrryyyyyy-- worrks on tokenized list\n",
        "      msg = processRepeatings(msg)\n",
        "\n",
        "      message_p.append(msg)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXWjHAcQoIEh",
        "outputId": "6058c8d5-b058-4f59-e21a-54abf2d6a14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "message_p[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['top dow 30 stocks highest payout ratio cvx pg ba xom ko',\n",
              " 'pg green red move 1 11 percentage 0 14 percentage',\n",
              " 'pg bought hopefully ol 39 gil made right decision',\n",
              " 'pg 322 overnight open 321 319',\n",
              " 'pg market share grabs continue procter amp gamble clorox',\n",
              " 'pg tough times never last tough people',\n",
              " 'midday mdlz pg blk stock suggestions selling short information sell price range charts expected sell returns option prices given midday video 7 21 2020 justrading youtube channel check would like daily suggested stocks report join us patreon collaborator supporter winner thank part 2',\n",
              " 'gnus boards littered worst kinds people beggars thieves prostitutes 39 looking pg gnus community comprised true ladies gentlemen want nothing best fellow man 39 honor serve alongside fine people',\n",
              " 'premier reports q2 production results mercedes restart update pg',\n",
              " 'peak profit last 6 expired option alerts pg 414 63 3 82 22 05 100 89 97 27 34 38']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkSpMpJWAG4u",
        "outputId": "9a0c601c-b0ba-4df9-e0ce-78c0d6f62963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "df_st1['message'] = message_p\n",
        "df_st1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>message</th>\n",
              "      <th>datetime</th>\n",
              "      <th>user</th>\n",
              "      <th>message_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PG</td>\n",
              "      <td>top dow 30 stocks highest payout ratio cvx pg ...</td>\n",
              "      <td>2020-07-21T21:37:30Z</td>\n",
              "      <td>1550174</td>\n",
              "      <td>229729267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg green red move 1 11 percentage 0 14 percentage</td>\n",
              "      <td>2020-07-21T20:28:32Z</td>\n",
              "      <td>1442893</td>\n",
              "      <td>229707089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg bought hopefully ol 39 gil made right decision</td>\n",
              "      <td>2020-07-21T19:49:53Z</td>\n",
              "      <td>2926317</td>\n",
              "      <td>229689416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg 322 overnight open 321 319</td>\n",
              "      <td>2020-07-21T19:42:24Z</td>\n",
              "      <td>308683</td>\n",
              "      <td>229686076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg market share grabs continue procter amp gam...</td>\n",
              "      <td>2020-07-21T19:31:05Z</td>\n",
              "      <td>2762379</td>\n",
              "      <td>229680970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31489</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg</td>\n",
              "      <td>2009-10-11T10:27:55Z</td>\n",
              "      <td>2251</td>\n",
              "      <td>656150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31490</th>\n",
              "      <td>PG</td>\n",
              "      <td>also dow pg bwa</td>\n",
              "      <td>2009-09-19T15:28:07Z</td>\n",
              "      <td>110</td>\n",
              "      <td>585492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31491</th>\n",
              "      <td>PG</td>\n",
              "      <td>-1</td>\n",
              "      <td>2009-09-18T16:39:17Z</td>\n",
              "      <td>259</td>\n",
              "      <td>583704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31492</th>\n",
              "      <td>PG</td>\n",
              "      <td>pretty solid rotation safety stocks today pfe ...</td>\n",
              "      <td>2009-09-18T15:02:22Z</td>\n",
              "      <td>581</td>\n",
              "      <td>583120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31493</th>\n",
              "      <td>PG</td>\n",
              "      <td>keep eye safety stocks pg jnj pfe etc people s...</td>\n",
              "      <td>2009-09-17T16:17:25Z</td>\n",
              "      <td>581</td>\n",
              "      <td>579505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31494 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      symbol  ... message_id\n",
              "0         PG  ...  229729267\n",
              "1         PG  ...  229707089\n",
              "2         PG  ...  229689416\n",
              "3         PG  ...  229686076\n",
              "4         PG  ...  229680970\n",
              "...      ...  ...        ...\n",
              "31489     PG  ...     656150\n",
              "31490     PG  ...     585492\n",
              "31491     PG  ...     583704\n",
              "31492     PG  ...     583120\n",
              "31493     PG  ...     579505\n",
              "\n",
              "[31494 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DraQK_uDcBU",
        "outputId": "935db3a8-ad30-4d01-beb8-d4f64a09a8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# Drop Retweets\n",
        "df_st1.drop(df_st1[df_st1['message'] == '-1'].index, inplace = True) \n",
        "df_st1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>message</th>\n",
              "      <th>datetime</th>\n",
              "      <th>user</th>\n",
              "      <th>message_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PG</td>\n",
              "      <td>top dow 30 stocks highest payout ratio cvx pg ...</td>\n",
              "      <td>2020-07-21T21:37:30Z</td>\n",
              "      <td>1550174</td>\n",
              "      <td>229729267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg green red move 1 11 percentage 0 14 percentage</td>\n",
              "      <td>2020-07-21T20:28:32Z</td>\n",
              "      <td>1442893</td>\n",
              "      <td>229707089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg bought hopefully ol 39 gil made right decision</td>\n",
              "      <td>2020-07-21T19:49:53Z</td>\n",
              "      <td>2926317</td>\n",
              "      <td>229689416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg 322 overnight open 321 319</td>\n",
              "      <td>2020-07-21T19:42:24Z</td>\n",
              "      <td>308683</td>\n",
              "      <td>229686076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg market share grabs continue procter amp gam...</td>\n",
              "      <td>2020-07-21T19:31:05Z</td>\n",
              "      <td>2762379</td>\n",
              "      <td>229680970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31488</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg massive call option action jan 2010</td>\n",
              "      <td>2009-10-20T20:05:11Z</td>\n",
              "      <td>1395</td>\n",
              "      <td>689435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31489</th>\n",
              "      <td>PG</td>\n",
              "      <td>pg</td>\n",
              "      <td>2009-10-11T10:27:55Z</td>\n",
              "      <td>2251</td>\n",
              "      <td>656150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31490</th>\n",
              "      <td>PG</td>\n",
              "      <td>also dow pg bwa</td>\n",
              "      <td>2009-09-19T15:28:07Z</td>\n",
              "      <td>110</td>\n",
              "      <td>585492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31492</th>\n",
              "      <td>PG</td>\n",
              "      <td>pretty solid rotation safety stocks today pfe ...</td>\n",
              "      <td>2009-09-18T15:02:22Z</td>\n",
              "      <td>581</td>\n",
              "      <td>583120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31493</th>\n",
              "      <td>PG</td>\n",
              "      <td>keep eye safety stocks pg jnj pfe etc people s...</td>\n",
              "      <td>2009-09-17T16:17:25Z</td>\n",
              "      <td>581</td>\n",
              "      <td>579505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31413 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      symbol  ... message_id\n",
              "0         PG  ...  229729267\n",
              "1         PG  ...  229707089\n",
              "2         PG  ...  229689416\n",
              "3         PG  ...  229686076\n",
              "4         PG  ...  229680970\n",
              "...      ...  ...        ...\n",
              "31488     PG  ...     689435\n",
              "31489     PG  ...     656150\n",
              "31490     PG  ...     585492\n",
              "31492     PG  ...     583120\n",
              "31493     PG  ...     579505\n",
              "\n",
              "[31413 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw-tgU3LsqtK",
        "outputId": "88f6e59e-18ec-4343-9515-831ff7b5ea6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#date time split code\n",
        "df_st1['datetime'] = df_st1['datetime'].astype('datetime64[ns]') #len(df_st1['datetime'])\n",
        "df_st1['Date'] = [d.date() for d in df_st1['datetime']]   #len(df_st1['Date'])\n",
        "df_st1['Time'] = [d.time() for d in df_st1['datetime']]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31413"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug8D4bzzT-rp",
        "outputId": "71675a52-ab40-47dd-891b-820cd82b37c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# df_st1['datetime'] = datetime.strptime(df_st1['datetime'].astype(str), \"%Y-%m-%dT%H:%M:%SZ\")   #2020-07-21T21:37:30Z\t\n",
        "# df_st1['datetime'] = pd.to_datetime(df_st1['datetime'], format='%b %d, %Y')\n",
        "import datetime\n",
        "from datetime import datetime, timedelta, date\n",
        "# def date_convert(date_to_convert):\n",
        "#      return datetime.strptime(date_to_convert, '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d')\n",
        "\n",
        "# df_st1['datetime'] = df_st1['datetime'].apply(date_convert)\n",
        "\n",
        "df_st1['datetime'].tail(5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31488   2009-10-20 20:05:11\n",
              "31489   2009-10-11 10:27:55\n",
              "31490   2009-09-19 15:28:07\n",
              "31492   2009-09-18 15:02:22\n",
              "31493   2009-09-17 16:17:25\n",
              "Name: datetime, dtype: datetime64[ns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8azyBIkhYgtP"
      },
      "source": [
        "from pandas_datareader import data as pdr\n",
        "!pip install yfinance --upgrade --no-cache-dir\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta, date\n",
        "# yf.pdr_override()\n",
        "start_dt = str(df_st1['Date'].iloc[-1])\n",
        "start_dt = str((datetime.strptime(start_dt, \"%Y-%m-%d\") + timedelta(days=-4)).strftime(\"%Y-%m-%d\"))\n",
        "end_dt = str(df_st1['Date'].iloc[0])\n",
        "end_dt =  str((datetime.strptime(end_dt, \"%Y-%m-%d\") + timedelta(days=4)).strftime(\"%Y-%m-%d\"))\n",
        "compny = df_st1['symbol'].iloc[0]\n",
        "PATH2 = PATH + compny+'_label2.2.csv'\n",
        "PATH = PATH+compny+'_label2.1.csv'\n",
        "if compny =='BRK.A':\n",
        "  compny = 'BRK-A'\n",
        "elif compny =='BRK.A':\n",
        "  compny ='BRK-B'\n",
        "elif compny =='VIX':\n",
        "  compny = '^VIX'\n",
        "else:\n",
        "  pass\n",
        "yahoo_data = yf.download(compny, start=start_dt, end=end_dt)\n",
        "yahoo_data.reset_index(level=0, inplace=True)\n",
        "yahoo_data.columns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo-CNqs6e5v_",
        "outputId": "b056b41d-8036-431f-cca7-5e560925d003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "import pandas as pd\n",
        "start_date = start_dt\n",
        "end_date = end_dt\n",
        "\n",
        "df_prices = pd.DataFrame(yahoo_data)\n",
        "# all_days = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "# df_prices.info\n",
        "df_prices['Date'] =  pd.to_datetime(df_prices['Date'], format='%Y-%m-%d')\n",
        "# df_prices = df_prices.sort_values(by=['Date'], ascending=[True])\n",
        "# df_prices.set_index('Date', inplace=True)\n",
        "# df_prices = df_prices.reindex(all_days).reset_index().rename(columns={\"index\":\"Date\"})\n",
        "# df_prices.reset_index(level=0, inplace=True)\n",
        "df_prices[:10]\n",
        "# df_prices.iloc[0][5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-09-14</td>\n",
              "      <td>55.230000</td>\n",
              "      <td>55.490002</td>\n",
              "      <td>55.049999</td>\n",
              "      <td>55.299999</td>\n",
              "      <td>39.092758</td>\n",
              "      <td>11139000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-09-15</td>\n",
              "      <td>55.560001</td>\n",
              "      <td>55.630001</td>\n",
              "      <td>54.889999</td>\n",
              "      <td>55.029999</td>\n",
              "      <td>38.901878</td>\n",
              "      <td>11674300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-09-16</td>\n",
              "      <td>55.080002</td>\n",
              "      <td>55.450001</td>\n",
              "      <td>54.610001</td>\n",
              "      <td>55.310001</td>\n",
              "      <td>39.099812</td>\n",
              "      <td>12932200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-09-17</td>\n",
              "      <td>55.330002</td>\n",
              "      <td>56.110001</td>\n",
              "      <td>55.299999</td>\n",
              "      <td>55.529999</td>\n",
              "      <td>39.255344</td>\n",
              "      <td>10665300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-09-18</td>\n",
              "      <td>56.570000</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>56.500000</td>\n",
              "      <td>57.320000</td>\n",
              "      <td>40.520733</td>\n",
              "      <td>25880200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2009-09-21</td>\n",
              "      <td>57.349998</td>\n",
              "      <td>57.459999</td>\n",
              "      <td>56.750000</td>\n",
              "      <td>57.099998</td>\n",
              "      <td>40.365208</td>\n",
              "      <td>11672200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2009-09-22</td>\n",
              "      <td>57.299999</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>56.959999</td>\n",
              "      <td>57.240002</td>\n",
              "      <td>40.464172</td>\n",
              "      <td>11517000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2009-09-23</td>\n",
              "      <td>57.340000</td>\n",
              "      <td>58.049999</td>\n",
              "      <td>57.150002</td>\n",
              "      <td>57.250000</td>\n",
              "      <td>40.471237</td>\n",
              "      <td>14611400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2009-09-24</td>\n",
              "      <td>57.380001</td>\n",
              "      <td>57.970001</td>\n",
              "      <td>57.299999</td>\n",
              "      <td>57.840000</td>\n",
              "      <td>40.888332</td>\n",
              "      <td>13589500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2009-09-25</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>58.500000</td>\n",
              "      <td>57.919998</td>\n",
              "      <td>58.009998</td>\n",
              "      <td>41.008514</td>\n",
              "      <td>13477500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date       Open       High        Low      Close  Adj Close    Volume\n",
              "0 2009-09-14  55.230000  55.490002  55.049999  55.299999  39.092758  11139000\n",
              "1 2009-09-15  55.560001  55.630001  54.889999  55.029999  38.901878  11674300\n",
              "2 2009-09-16  55.080002  55.450001  54.610001  55.310001  39.099812  12932200\n",
              "3 2009-09-17  55.330002  56.110001  55.299999  55.529999  39.255344  10665300\n",
              "4 2009-09-18  56.570000  57.509998  56.500000  57.320000  40.520733  25880200\n",
              "5 2009-09-21  57.349998  57.459999  56.750000  57.099998  40.365208  11672200\n",
              "6 2009-09-22  57.299999  57.509998  56.959999  57.240002  40.464172  11517000\n",
              "7 2009-09-23  57.340000  58.049999  57.150002  57.250000  40.471237  14611400\n",
              "8 2009-09-24  57.380001  57.970001  57.299999  57.840000  40.888332  13589500\n",
              "9 2009-09-25  58.000000  58.500000  57.919998  58.009998  41.008514  13477500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIUREs1AiUDI",
        "outputId": "a9aafdd3-e056-4ece-cacf-1fbc4764f2e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "####Comparing Close price and Open Price of Same day (close-open)/open\n",
        "price_change = []\n",
        "for i in range(len(df_prices)):\n",
        "  change = ((df_prices.iloc[i][4]-df_prices.iloc[i][1])/df_prices.iloc[i][1])*100\n",
        "  price_change.append(change)\n",
        "df_prices['PriceChange'] = price_change\n",
        "df_prices.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>PriceChange</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-09-14</td>\n",
              "      <td>55.230000</td>\n",
              "      <td>55.490002</td>\n",
              "      <td>55.049999</td>\n",
              "      <td>55.299999</td>\n",
              "      <td>39.092758</td>\n",
              "      <td>11139000</td>\n",
              "      <td>0.126742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-09-15</td>\n",
              "      <td>55.560001</td>\n",
              "      <td>55.630001</td>\n",
              "      <td>54.889999</td>\n",
              "      <td>55.029999</td>\n",
              "      <td>38.901878</td>\n",
              "      <td>11674300</td>\n",
              "      <td>-0.953928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-09-16</td>\n",
              "      <td>55.080002</td>\n",
              "      <td>55.450001</td>\n",
              "      <td>54.610001</td>\n",
              "      <td>55.310001</td>\n",
              "      <td>39.099812</td>\n",
              "      <td>12932200</td>\n",
              "      <td>0.417574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-09-17</td>\n",
              "      <td>55.330002</td>\n",
              "      <td>56.110001</td>\n",
              "      <td>55.299999</td>\n",
              "      <td>55.529999</td>\n",
              "      <td>39.255344</td>\n",
              "      <td>10665300</td>\n",
              "      <td>0.361462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-09-18</td>\n",
              "      <td>56.570000</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>56.500000</td>\n",
              "      <td>57.320000</td>\n",
              "      <td>40.520733</td>\n",
              "      <td>25880200</td>\n",
              "      <td>1.325791</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date       Open       High  ...  Adj Close    Volume  PriceChange\n",
              "0 2009-09-14  55.230000  55.490002  ...  39.092758  11139000     0.126742\n",
              "1 2009-09-15  55.560001  55.630001  ...  38.901878  11674300    -0.953928\n",
              "2 2009-09-16  55.080002  55.450001  ...  39.099812  12932200     0.417574\n",
              "3 2009-09-17  55.330002  56.110001  ...  39.255344  10665300     0.361462\n",
              "4 2009-09-18  56.570000  57.509998  ...  40.520733  25880200     1.325791\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUk4qemapc7l",
        "outputId": "488cf029-e6c8-4b64-acc6-6d87c46688ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tweet_dates = (df_st1['Date'].astype(str)).tolist() #len(tweet_dates)\n",
        "stock_dates = (df_prices['Date'].astype(str)).tolist() #len(stock_dates)\n",
        "percentage_change = df_prices['PriceChange'].tolist() #len(percentage_change)\n",
        "tweet_time = df_st1['Time'].tolist() \n",
        "# percentage_date = (df_prices['Date'].astype(str)).tolist() #len(percentage_date)\n",
        "print(len(tweet_dates))\n",
        "print(len(stock_dates))\n",
        "print(len(percentage_change))\n",
        "print(len(tweet_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j3-_J2T8hLl",
        "outputId": "d08db953-726b-48a0-afd4-b86f694a65fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "check =1\n",
        "for da in tweet_dates:\n",
        "  # if check == 1:\n",
        "  #   if da not in stock_dates:\n",
        "  #     continue\n",
        "  # else:\n",
        "  #   check = 2\n",
        "  if da not in stock_dates:\n",
        "    flag1 = False\n",
        "    temp1_da = da\n",
        "    # print(temp1_da)\n",
        "    while flag1 == False:\n",
        "      temp1_da = datetime.strptime(temp1_da, \"%Y-%m-%d\") + timedelta(days=-1)\n",
        "      temp1_da = datetime.strftime(temp1_da, \"%Y-%m-%d\")\n",
        "      if temp1_da not in stock_dates:\n",
        "        continue\n",
        "      else:\n",
        "        flag1=True\n",
        "        flag2 = False\n",
        "        temp2_da = da\n",
        "        while flag2 == False:\n",
        "          temp2_da = datetime.strptime(temp2_da, \"%Y-%m-%d\") + timedelta(days=1)\n",
        "          # print('check3', temp2_da)\n",
        "          temp2_da = datetime.strftime(temp2_da, \"%Y-%m-%d\")\n",
        "          # print('check4', temp2_da)\n",
        "          if temp2_da not in stock_dates:\n",
        "            # print('check3')\n",
        "            continue\n",
        "          else:\n",
        "            flag2= True\n",
        "            day_before_change = 0\n",
        "            day_after_change = 0\n",
        "            count = 0\n",
        "            for dat, per_change in zip(stock_dates,percentage_change):\n",
        "              count\n",
        "              if temp1_da == dat:\n",
        "                day_before_change = per_change\n",
        "                count = count +1\n",
        "              elif temp2_da == dat:\n",
        "                day_after_change = per_change\n",
        "                count = count +1\n",
        "              if count == 2:\n",
        "                \n",
        "                mean_change = (day_before_change+day_after_change)/2\n",
        "                # print(da,mean_change)\n",
        "                stock_dates.append(da)\n",
        "                percentage_change.append(mean_change)\n",
        "                break\n",
        "              else:\n",
        "                continue\n",
        "print(len(percentage_change))\n",
        "print(len(stock_dates))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3523\n",
            "3523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXRGYIOnHhtB",
        "outputId": "ba767f2a-f080-4009-b70b-d01ef639db50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(len(percentage_change))\n",
        "print(len(stock_dates))\n",
        "print(len(tweet_dates))\n",
        "a = set(stock_dates) \n",
        "print(len(a))\n",
        "b = set(tweet_dates) \n",
        "print(len(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3523\n",
            "3523\n",
            "31413\n",
            "3523\n",
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXW9RS6w6lez",
        "outputId": "54e7fd4c-a7bf-4d47-8c87-07190c29c8be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "tweet_polarity = []\n",
        "# stock_change = []\n",
        "# for date,pc in zip(stock_dates,percentage_change): \n",
        "#   stock_change.append((date,pc))    #len(stock_change)\n",
        "msg_tweet = df_st1['message'].tolist()  #len(msg_tweet)\n",
        "# msg_grouped = []\n",
        "# for date,msg in zip(tweet_dates,msg_tweet): #len(msg_grouped)\n",
        "#   msg_grouped.append((date,msg))\n",
        "\n",
        "counter = 0\n",
        "for date, pc in zip(stock_dates,percentage_change):\n",
        "  for datetweet in tweet_dates:\n",
        "\n",
        "    if date == datetweet:\n",
        "      if pc > 0.5:\n",
        "        tweet_polarity.append(1)\n",
        "      elif pc < -0.5:\n",
        "        tweet_polarity.append(-1)\n",
        "      else:\n",
        "        tweet_polarity.append( 0)\n",
        "\n",
        "print(len(tweet_polarity))\n",
        "print(len(tweet_dates))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31413\n",
            "31413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbXTW27jv4mS"
      },
      "source": [
        "dict_sameday = {'date': tweet_dates,'message': msg_tweet, 'label': tweet_polarity, 'time': tweet_time}  \n",
        "    \n",
        "df_labelled = pd.DataFrame(dict_sameday) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYFQtpa3wl-c"
      },
      "source": [
        "# df_labelled.to_csv(PATH, header=True, index=False, encoding='utf_8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVmMMQ_WsTsz"
      },
      "source": [
        "def get_label(ch):\n",
        "  if ch>0.5:\n",
        "    return 1\n",
        "  elif ch<-0.5:\n",
        "    return -1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTrB6IiQsUas"
      },
      "source": [
        "date_label = []\n",
        "dates_index = []\n",
        "stock_close = df_prices['Close']\n",
        "for i in range(1,len(stock_close)):\n",
        "  label=99\n",
        "  # daydiff = datetime.strptime(datetime.strftime(stock_dates[i], \"%Y-%m-%d\"), \"%Y-%m-%d\") - datetime.strptime(datetime.strftime(stock_dates[i-1], \"%Y-%m-%d\"),\"%Y-%m-%d\")\n",
        "  daydiff = datetime.strptime(stock_dates[i], \"%Y-%m-%d\") - datetime.strptime(stock_dates[i-1], \"%Y-%m-%d\")\n",
        "  if daydiff.days == 1:\n",
        "    change = ((stock_close[i]-stock_close[i-1])/stock_close[i-1])*100\n",
        "    if change>0.5:\n",
        "      label = 1\n",
        "    elif change<-0.5:\n",
        "      label = -1\n",
        "    else:\n",
        "      label = 0\n",
        "    date_label.append((datetime.strptime(stock_dates[i], \"%Y-%m-%d\"), change,label))\n",
        "    dates_index.append(datetime.strptime(stock_dates[i], \"%Y-%m-%d\"))\n",
        "  else:\n",
        "    daysgap = daydiff.days\n",
        "    daysadd = 1\n",
        "    change_l = ((stock_close[i]-stock_close[i-1])/stock_close[i-1])*100\n",
        "    while daysgap >1:\n",
        "      # gapDate = datetime.strptime(datetime.strftime(stock_dates[i-1], \"%Y-%m-%d\"), \"%Y-%m-%d\") + timedelta(days=daysadd)\n",
        "      gapDate = datetime.strptime(stock_dates[i-1], \"%Y-%m-%d\") + timedelta(days=daysadd)\n",
        "      change_g_mean = (change_l + date_label[-1][1])/2\n",
        "      if change_g_mean>0.5:\n",
        "        label = 1\n",
        "      elif change_g_mean<-0.5:\n",
        "        label = -1\n",
        "      else:\n",
        "        label = 0\n",
        "      date_label.append((datetime.strftime(gapDate, \"%Y-%m-%d\"), change_g_mean,label))\n",
        "      dates_index.append(datetime.strftime(gapDate, \"%Y-%m-%d\"))\n",
        "      daysgap = daysgap - 1\n",
        "      daysadd = daysadd + 1\n",
        "    label = get_label(change_l)\n",
        "    date_label.append((datetime.strptime(stock_dates[i], \"%Y-%m-%d\"), change_l,label))\n",
        "    dates_index.append(datetime.strptime(stock_dates[i], \"%Y-%m-%d\"))\n",
        "\n",
        "  # temp2_da = datetime.strftime(temp2_da, \"%Y-%m-%d\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9kBCuU8sadM"
      },
      "source": [
        "polarity = []\n",
        "change = []\n",
        "for index, row in df_st1.iterrows():\n",
        "  \n",
        "  d1 = datetime.strftime(row['Date'], \"%Y-%m-%d\")   #2020-07-21T21:37:30Z\t\n",
        "  d2 = datetime.strptime(d1, \"%Y-%m-%d\")\n",
        "  if d2 not in dates_index:\n",
        "    change.append(-99)\n",
        "    polarity.append(-99)\n",
        "    continue\n",
        "  d_index = dates_index.index(d2)\n",
        "  polarity.append(date_label[d_index][2])\n",
        "  change.append(date_label[d_index][1])\n",
        "# df_st1['change'] = change\n",
        "df_st1['label'] = polarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71anj4UKFzBC"
      },
      "source": [
        "# Drop polarity -99\n",
        "df_st1.drop(df_st1[df_st1['label'] == -99].index, inplace = True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDmTkUZfERZO"
      },
      "source": [
        "# df_st1['datetime'] = df_st1['datetime'].astype('datetime64[ns]') #len(df_st1['datetime'])\n",
        "# df_st1['Date'] = [d.date() for d in df_st1['datetime']]   #len(df_st1['Date'])\n",
        "# df_st1['Time'] = [d.time() for d in df_st1['datetime']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC_M3lYRCpLZ"
      },
      "source": [
        "# dict_prevday = {'date': tweet_dates,'message': msg_tweet, 'label': polarity, 'time': tweet_time}  \n",
        "    \n",
        "# df_labelled = pd.DataFrame(dict_sameday) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRTSb5W6sdGg"
      },
      "source": [
        "df_st1.to_csv(PATH2, header=True, index=False, encoding='utf_8')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}