{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Labelling_Approach2_FinalVersion.ipynb","provenance":[],"collapsed_sections":["n4yjzBW1NSCy"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HkqDSyOVDpRD"},"source":["# Install, Import, Mount statements"]},{"cell_type":"code","metadata":{"id":"_gXtdFlzndWh","colab":{"base_uri":"https://localhost:8080/","height":453},"outputId":"ca85f27a-9961-4edc-edbc-15bd6e46af8e"},"source":["!pip install contractions\n","!pip install emoji\n","!pip install ekphrasis\n","\n","import pandas as pd\n","import re\n","import emoji\n","import nltk\n","import contractions\n","import torch\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","# from nltk.tokenize import word_tokenize\n","from nltk.tokenize import TweetTokenizer \n","from nltk.corpus import stopwords as sw\n","from nltk.tokenize import word_tokenize \n","from nltk.tokenize.treebank import TreebankWordDetokenizer\n","import requests \n","from pprint import pprint\n","import numpy as np\n","from nltk.stem import PorterStemmer\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime\n","from tensorflow import keras\n","\n","import os\n","import pprint\n","import json\n","import random\n","import string\n","import sys\n","from ekphrasis.classes.segmenter import Segmenter\n","import itertools"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.25)\n","Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n","Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n","Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n","Requirement already satisfied: ekphrasis in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (3.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (3.2.5)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (0.4.4)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (5.8)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (4.41.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (1.1.0)\n","Requirement already satisfied: ujson in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (4.0.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ekphrasis) (1.18.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ekphrasis) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->ekphrasis) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->ekphrasis) (0.2.5)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HSZ7lIUN3ofk","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"b2c2dc62-ac21-4e96-94a6-982d4dc48557"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vFOsh5pJq2QZ"},"source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pandas as pd\n","# Authenticate the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Opcbq6SN7HY_"},"source":["#Function to load files of different companies\n","def get_compData(comp):\n","  if comp =='AAPL':\n","    # AAPL: https://drive.google.com/file/d/1diLooyj8DtyyxwiihpbTJdfY4D98irLE/view?usp=sharing\n","    id = '1diLooyj8DtyyxwiihpbTJdfY4D98irLE'\n","    downloaded1 = drive.CreateFile({'id':id}) \n","    downloaded1.GetContentFile('stocktwits_AAPL.csv')\n","    df_st1 = pd.read_csv('stocktwits_AAPL.csv')\n","    return df_st1\n","  elif comp=='ADBE':\n","    # ADBE: https://drive.google.com/file/d/1SMyRg8aUnnQTbukVadBo814qdS6xDnP1/view?usp=sharing\n","    id = '1SMyRg8aUnnQTbukVadBo814qdS6xDnP1'\n","    downloaded2 = drive.CreateFile({'id':id}) \n","    downloaded2.GetContentFile('stocktwits_ADBE.csv')\n","    df_st2 = pd.read_csv('stocktwits_ADBE.csv')\n","    return df_st2\n","  elif comp=='AMZN':\n","    # AMZN: https://drive.google.com/file/d/1ffmFOrlcaTCCByKMq7E1LCXXK6daMkB_/view?usp=sharing\n","    id = '1ffmFOrlcaTCCByKMq7E1LCXXK6daMkB_'\n","    downloaded3 = drive.CreateFile({'id':id}) \n","    downloaded3.GetContentFile('stocktwits_AMZN.csv')\n","    df_st3 = pd.read_csv('stocktwits_AMZN.csv')\n","    return df_st3\n","  elif comp=='BAC':\n","    # BAC: https://drive.google.com/file/d/1HeaKJtlSz2xiLT3sx5FLdYmzCkVDGIjW/view?usp=sharing\n","    id = '1HeaKJtlSz2xiLT3sx5FLdYmzCkVDGIjW'\n","    downloaded4 = drive.CreateFile({'id':id}) \n","    downloaded4.GetContentFile('stocktwits_BAC.csv')\n","    df_st4 = pd.read_csv('stocktwits_BAC.csv')\n","    return df_st4\n","\n","  elif comp=='BRK.A':\n","\n","    #BRK_A: https://drive.google.com/file/d/1HeQhAU20YyT1tRCD-yN83vrUGY7jDDSt/view?usp=sharing\n","    id = '1HeQhAU20YyT1tRCD-yN83vrUGY7jDDSt'\n","    downloaded5 = drive.CreateFile({'id':id}) \n","    downloaded5.GetContentFile('stocktwits_BRK_A.csv')\n","    df_st5 = pd.read_csv('stocktwits_BRK_A.csv')\n","    return df_st5\n","  elif comp=='BRK.B':\n","    #BRK_B: https://drive.google.com/file/d/1FRrwrIVJVyFqg025SWasKW84qOJMhe84/view?usp=sharing\n","    id = '1FRrwrIVJVyFqg025SWasKW84qOJMhe84'\n","    downloaded6 = drive.CreateFile({'id':id}) \n","    downloaded6.GetContentFile('stocktwits_BRK_B.csv')\n","    df_st6 = pd.read_csv('stocktwits_BRK_B.csv')\n","    return df_st6\n","  elif comp=='DIA':\n","    #DIA: https://drive.google.com/file/d/1riZ8IdkupLre9NQ7McBO21wDFVX_NPvg/view?usp=sharing\n","    id = '1riZ8IdkupLre9NQ7McBO21wDFVX_NPvg'\n","    downloaded7 = drive.CreateFile({'id':id}) \n","    downloaded7.GetContentFile('stocktwits_DIA.csv')\n","    df_st7 = pd.read_csv('stocktwits_DIA.csv')\n","    return df_st7\n","  elif comp=='DIS':\n","    #DIS: https://drive.google.com/file/d/1y5IT3gA_yIJnFLTsxy1GHdIY4SHwj84Y/view?usp=sharing\n","    id = '1y5IT3gA_yIJnFLTsxy1GHdIY4SHwj84Y'\n","    downloaded8 = drive.CreateFile({'id':id}) \n","    downloaded8.GetContentFile('stocktwits_DIS.csv')\n","    df_st8 = pd.read_csv('stocktwits_DIS.csv')\n","    return df_st8\n","  elif comp=='FB':\n","    #FB: https://drive.google.com/file/d/1x1FugJhUQx9xKWS9LYnio1MU8oi5iuTc/view?usp=sharing\n","    id = '1x1FugJhUQx9xKWS9LYnio1MU8oi5iuTc'\n","    downloaded9 = drive.CreateFile({'id':id}) \n","    downloaded9.GetContentFile('stocktwits_FB.csv')\n","    df_st9 = pd.read_csv('stocktwits_FB.csv')\n","    return df_st9\n","  elif comp=='GOOG':\n","    #GOOG: https://drive.google.com/file/d/1UMnPXfG_XkgLJAQ2VtLvMPBPZhN68Ezw/view?usp=sharing\n","    id = '1UMnPXfG_XkgLJAQ2VtLvMPBPZhN68Ezw'\n","    downloaded10 = drive.CreateFile({'id':id}) \n","    downloaded10.GetContentFile('stocktwits_GOOG.csv')\n","    df_st10 = pd.read_csv('stocktwits_GOOG.csv')\n","    return df_st10\n","  elif comp=='GOOGL':\n","    #GOOGL: https://drive.google.com/file/d/1NbCpQX0sTgXsqcW7xMbkrDPlAOscIoTL/view?usp=sharing\n","    id = '1NbCpQX0sTgXsqcW7xMbkrDPlAOscIoTL'\n","    downloaded11 = drive.CreateFile({'id':id}) \n","    downloaded11.GetContentFile('stocktwits_GOOGL.csv')\n","    df_st11 = pd.read_csv('stocktwits_GOOGL.csv')\n","    return df_st11\n","  elif comp=='HD':\n","    #HD: https://drive.google.com/file/d/10wbCzJMcjLWAqrlEtHlWieIrq7dyolG2/view?usp=sharing\n","    id = '10wbCzJMcjLWAqrlEtHlWieIrq7dyolG2'\n","    downloaded12 = drive.CreateFile({'id':id}) \n","    downloaded12.GetContentFile('stocktwits_HD.csv')\n","    df_st12 = pd.read_csv('stocktwits_HD.csv')\n","    return df_st12\n","  elif comp=='INTC':\n","    # INTC: https://drive.google.com/file/d/1k1-NSl8qLTa2oDs1G8CFC4CJzkv9mugw/view?usp=sharing \n","    id = '1k1-NSl8qLTa2oDs1G8CFC4CJzkv9mugw'\n","    downloaded13 = drive.CreateFile({'id':id}) \n","    downloaded13.GetContentFile('stocktwits_INTC.csv')\n","    df_st13 = pd.read_csv('stocktwits_INTC.csv')\n","    return df_st13\n","  elif comp=='JNJ':\n","    # JNJ: https://drive.google.com/file/d/1Qiwu9vbDYU527szR8waaFDoFCyY4i_bc/view?usp=sharing\n","    id = '1Qiwu9vbDYU527szR8waaFDoFCyY4i_bc'\n","    downloaded14 = drive.CreateFile({'id':id}) \n","    downloaded14.GetContentFile('stocktwits_JNJ.csv')\n","    df_st14 = pd.read_csv('stocktwits_JNJ.csv')\n","    return df_st14\n","  elif comp=='NFLX':\n","    # NFLX: https://drive.google.com/file/d/1DdJ8MPdgt9bxF3ZagkWUp45N4RMQ8Al6/view?usp=sharing\n","    id = '1DdJ8MPdgt9bxF3ZagkWUp45N4RMQ8Al6'\n","    downloaded15 = drive.CreateFile({'id':id}) \n","    downloaded15.GetContentFile('stocktwits_NFLX.csv')\n","    df_st15 = pd.read_csv('stocktwits_NFLX.csv')\n","    return df_st15\n","  elif comp=='PG':\n","    # PG: https://drive.google.com/file/d/1tlueLaJhlduNMgRHk8Omkog5nNI8I8Yk/view?usp=sharing\n","    id = '1tlueLaJhlduNMgRHk8Omkog5nNI8I8Yk'\n","    downloaded16 = drive.CreateFile({'id':id}) \n","    downloaded16.GetContentFile('stocktwits_PG.csv')\n","    df_st16 = pd.read_csv('stocktwits_PG.csv')\n","    return df_st16\n","  elif comp=='QQQ':\n","    # QQQ: https://drive.google.com/file/d/1gUsl5L4VBgsL9oqBxaUdk6tA9r4VxDjo/view?usp=sharing\n","    id = '1gUsl5L4VBgsL9oqBxaUdk6tA9r4VxDjo'\n","    downloaded17 = drive.CreateFile({'id':id}) \n","    downloaded17.GetContentFile('stocktwits_QQQ.csv')\n","    df_st17 = pd.read_csv('stocktwits_QQQ.csv')\n","    return df_st17\n","  elif comp=='SPY':\n","    # SPY: https://drive.google.com/file/d/10s-zYQPIqlkNsUahgzDRqJGw0VAkn-R1/view?usp=sharing\n","    id = '10s-zYQPIqlkNsUahgzDRqJGw0VAkn-R1'\n","    downloaded18 = drive.CreateFile({'id':id}) \n","    downloaded18.GetContentFile('stocktwits_SPY.csv')\n","    df_st18 = pd.read_csv('stocktwits_SPY.csv')\n","    return df_st18\n","  elif comp=='T':\n","    # T: https://drive.google.com/file/d/1rk3PsikhgrA7MxV28tUbzj7EOn9K5Ixu/view?usp=sharing\n","    id = '1rk3PsikhgrA7MxV28tUbzj7EOn9K5Ixu'\n","    downloaded19 = drive.CreateFile({'id':id}) \n","    downloaded19.GetContentFile('stocktwits_T.csv')\n","    df_st19 = pd.read_csv('stocktwits_T.csv')\n","    return df_st19\n","  elif comp=='TSLA':\n","    # TSLA: https://drive.google.com/file/d/1on57uk2gd_CLsnj1dcRfuB_KsYydzEp2/view?usp=sharing\n","    id = '1on57uk2gd_CLsnj1dcRfuB_KsYydzEp2'\n","    downloaded20 = drive.CreateFile({'id':id}) \n","    downloaded20.GetContentFile('stocktwits_TSLA.csv')\n","    df_st20 = pd.read_csv('stocktwits_TSLA.csv')\n","    return df_st20\n","  elif comp=='UNH':\n","    # UNH: https://drive.google.com/file/d/1zguMHb3pL2tCT4TYV8XJcP-dWTcq28mY/view?usp=sharing\n","    id = '1zguMHb3pL2tCT4TYV8XJcP-dWTcq28mY'\n","    downloaded21 = drive.CreateFile({'id':id}) \n","    downloaded21.GetContentFile('stocktwits_UNH.csv')\n","    df_st21 = pd.read_csv('stocktwits_UNH.csv')\n","    return df_st21\n","  elif comp=='V':\n","    # V: https://drive.google.com/file/d/1qLI1Rsyf2ebZu53I8QaFuOQSeTyZShLg/view?usp=sharing\n","    id = '1qLI1Rsyf2ebZu53I8QaFuOQSeTyZShLg'\n","    downloaded22 = drive.CreateFile({'id':id}) \n","    downloaded22.GetContentFile('stocktwits_V.csv')\n","    df_st22 = pd.read_csv('stocktwits_V.csv')\n","    return df_st22\n","  elif comp=='VIX':\n","    # VIX: https://drive.google.com/file/d/1SoIue0nfsn_GGMOroFg3tEp8re-v7PnJ/view?usp=sharing\n","    id = '1SoIue0nfsn_GGMOroFg3tEp8re-v7PnJ'\n","    downloaded23 = drive.CreateFile({'id':id}) \n","    downloaded23.GetContentFile('stocktwits_VIX.csv')\n","    df_st23 = pd.read_csv('stocktwits_VIX.csv')\n","    return df_st23\n","  elif comp=='VZ':\n","    # VZ: https://drive.google.com/file/d/1ddISbB0qfDpM69senqEmmf6xbNWOpNUJ/view?usp=sharing\n","    id = '1ddISbB0qfDpM69senqEmmf6xbNWOpNUJ'\n","    downloaded24 = drive.CreateFile({'id':id}) \n","    downloaded24.GetContentFile('stocktwits_VZ.csv')\n","    df_st24 = pd.read_csv('stocktwits_VZ.csv')\n","    return df_st24\n","  elif comp=='WMT':\n","    # WMT: https://drive.google.com/file/d/14Zdh1ZCj5RxZltXknG3Qisxhwzge5rkV/view?usp=sharing\n","    id = '14Zdh1ZCj5RxZltXknG3Qisxhwzge5rkV'\n","    downloaded25 = drive.CreateFile({'id':id}) \n","    downloaded25.GetContentFile('stocktwits_WMT.csv')\n","    df_st25 = pd.read_csv('stocktwits_WMT.csv')\n","    return df_st25"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2GSEYpSN22v-"},"source":["#Change the company name here\n","df_st1 = get_compData('TSLA')\n","#change the directory you want to save the file\n","PATH='/content/drive/My Drive/sentiment_data/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8KjCLPk5DK-","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"f8f028cf-9dbd-4a3d-f922-dc0c0e76d9e9"},"source":["df_st1.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>symbol</th>\n","      <th>message</th>\n","      <th>datetime</th>\n","      <th>user</th>\n","      <th>message_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TSLA</td>\n","      <td>$ECOR I&amp;#39;m adding here. Covid play with big...</td>\n","      <td>2020-07-16T23:08:58Z</td>\n","      <td>1659003</td>\n","      <td>228472656</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TSLA</td>\n","      <td>$TSLA trash</td>\n","      <td>2020-07-16T23:08:47Z</td>\n","      <td>3796654</td>\n","      <td>228472618</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TSLA</td>\n","      <td>$TSLA https://www.tesmanian.com/blogs/tesmania...</td>\n","      <td>2020-07-16T23:06:01Z</td>\n","      <td>335497</td>\n","      <td>228472036</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TSLA</td>\n","      <td>$TSLA what&amp;#39;s happening here? Considerin se...</td>\n","      <td>2020-07-16T23:04:50Z</td>\n","      <td>3572445</td>\n","      <td>228471810</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TSLA</td>\n","      <td>$BB https://publishing.ninja/V4/page/10630/414...</td>\n","      <td>2020-07-16T23:03:55Z</td>\n","      <td>1711636</td>\n","      <td>228471610</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  symbol  ... message_id\n","0   TSLA  ...  228472656\n","1   TSLA  ...  228472618\n","2   TSLA  ...  228472036\n","3   TSLA  ...  228471810\n","4   TSLA  ...  228471610\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"ipxYrd8yLgDc","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"c68d5b93-dfd0-404d-9c34-1cf74b3077f5"},"source":["df_st1.tail()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>symbol</th>\n","      <th>message</th>\n","      <th>datetime</th>\n","      <th>user</th>\n","      <th>message_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1799481</th>\n","      <td>TSLA</td>\n","      <td>@howardlindzon i think it starts trading tomor...</td>\n","      <td>2010-06-29T00:46:52Z</td>\n","      <td>27</td>\n","      <td>1540976</td>\n","    </tr>\n","    <tr>\n","      <th>1799482</th>\n","      <td>TSLA</td>\n","      <td>congrats to Tesla $tsla for going public today...</td>\n","      <td>2010-06-29T00:42:24Z</td>\n","      <td>5</td>\n","      <td>1540973</td>\n","    </tr>\n","    <tr>\n","      <th>1799483</th>\n","      <td>TSLA</td>\n","      <td>If you have sat in a $TSLA you know its very s...</td>\n","      <td>2010-06-29T00:39:41Z</td>\n","      <td>289</td>\n","      <td>1540967</td>\n","    </tr>\n","    <tr>\n","      <th>1799484</th>\n","      <td>TSLA</td>\n","      <td>RT @YoYo_Trader @ppearlman  That IPO seems lik...</td>\n","      <td>2010-06-28T20:46:15Z</td>\n","      <td>27</td>\n","      <td>1540535</td>\n","    </tr>\n","    <tr>\n","      <th>1799485</th>\n","      <td>TSLA</td>\n","      <td>New Issue Tesla Motors Stream now live on Sto...</td>\n","      <td>2010-06-28T20:40:16Z</td>\n","      <td>27</td>\n","      <td>1540514</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        symbol  ... message_id\n","1799481   TSLA  ...    1540976\n","1799482   TSLA  ...    1540973\n","1799483   TSLA  ...    1540967\n","1799484   TSLA  ...    1540535\n","1799485   TSLA  ...    1540514\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"7HK0IehsNI3y"},"source":["# Yahoo API"]},{"cell_type":"code","metadata":{"id":"Dw-tgU3LsqtK","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"3b172223-33d4-4042-9421-c5d8b77fd322"},"source":["#date time split code\n","import datetime\n","from datetime import datetime, timedelta, date\n","df_st1['datetime'] = df_st1['datetime'].astype('datetime64[ns]') #len(df_st1['datetime'])\n","df_st1['Date'] = [d.date() for d in df_st1['datetime']]   #len(df_st1['Date'])\n","df_st1['Time'] = [d.time() for d in df_st1['datetime']]\n","df_st1['datetime'].tail(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1799481   2010-06-29 00:46:52\n","1799482   2010-06-29 00:42:24\n","1799483   2010-06-29 00:39:41\n","1799484   2010-06-28 20:46:15\n","1799485   2010-06-28 20:40:16\n","Name: datetime, dtype: datetime64[ns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"8azyBIkhYgtP","colab":{"base_uri":"https://localhost:8080/","height":297},"outputId":"e6bded9e-81cf-4cb5-8d7b-9f747427b003"},"source":["from pandas_datareader import data as pdr\n","!pip install yfinance --upgrade --no-cache-dir\n","import yfinance as yf\n","from datetime import datetime, timedelta, date\n","# yf.pdr_override()\n","start_dt = str(df_st1['Date'].iloc[-1])\n","start_dt = str((datetime.strptime(start_dt, \"%Y-%m-%d\") + timedelta(days=-1)).strftime(\"%Y-%m-%d\"))\n","end_dt = str(df_st1['Date'].iloc[0])\n","end_dt =  str((datetime.strptime(end_dt, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\"))\n","compny = df_st1['symbol'].iloc[0]\n","PATH2 = PATH + compny+'_label2.2.csv'\n","PATH = PATH+compny+'_label2.1.csv'\n","if compny =='BRK.A':\n","  compny = 'BRK-A'\n","elif compny =='BRK.B':\n","  compny ='BRK-B'\n","elif compny =='VIX':\n","  compny = '^VIX'\n","else:\n","  pass\n","yahoo_data = yf.download(compny, start=start_dt, end=end_dt)\n","yahoo_data.reset_index(level=0, inplace=True)\n","yahoo_data.columns\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: yfinance in /usr/local/lib/python3.6/dist-packages (0.1.55)\n","Requirement already satisfied, skipping upgrade: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.23.0)\n","Requirement already satisfied, skipping upgrade: lxml>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from yfinance) (4.6.1)\n","Requirement already satisfied, skipping upgrade: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n","Requirement already satisfied, skipping upgrade: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.1.3)\n","Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.18.5)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n","Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n","[*********************100%***********************]  1 of 1 completed\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"jo-CNqs6e5v_","colab":{"base_uri":"https://localhost:8080/","height":355},"outputId":"db17e944-108b-4967-8049-8b864a9d56fc"},"source":["import pandas as pd\n","start_date = start_dt\n","end_date = end_dt\n","\n","df_prices = pd.DataFrame(yahoo_data)\n","\n","df_prices['Date'] =  pd.to_datetime(df_prices['Date'], format='%Y-%m-%d')\n","\n","df_prices[:10]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Adj Close</th>\n","      <th>Volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2010-06-29</td>\n","      <td>3.800</td>\n","      <td>5.000</td>\n","      <td>3.508</td>\n","      <td>4.778</td>\n","      <td>4.778</td>\n","      <td>93831500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2010-06-30</td>\n","      <td>5.158</td>\n","      <td>6.084</td>\n","      <td>4.660</td>\n","      <td>4.766</td>\n","      <td>4.766</td>\n","      <td>85935500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2010-07-01</td>\n","      <td>5.000</td>\n","      <td>5.184</td>\n","      <td>4.054</td>\n","      <td>4.392</td>\n","      <td>4.392</td>\n","      <td>41094000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2010-07-02</td>\n","      <td>4.600</td>\n","      <td>4.620</td>\n","      <td>3.742</td>\n","      <td>3.840</td>\n","      <td>3.840</td>\n","      <td>25699000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2010-07-06</td>\n","      <td>4.000</td>\n","      <td>4.000</td>\n","      <td>3.166</td>\n","      <td>3.222</td>\n","      <td>3.222</td>\n","      <td>34334500</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2010-07-07</td>\n","      <td>3.280</td>\n","      <td>3.326</td>\n","      <td>2.996</td>\n","      <td>3.160</td>\n","      <td>3.160</td>\n","      <td>34608500</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2010-07-08</td>\n","      <td>3.228</td>\n","      <td>3.504</td>\n","      <td>3.114</td>\n","      <td>3.492</td>\n","      <td>3.492</td>\n","      <td>38557000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2010-07-09</td>\n","      <td>3.516</td>\n","      <td>3.580</td>\n","      <td>3.310</td>\n","      <td>3.480</td>\n","      <td>3.480</td>\n","      <td>20253000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2010-07-12</td>\n","      <td>3.590</td>\n","      <td>3.614</td>\n","      <td>3.400</td>\n","      <td>3.410</td>\n","      <td>3.410</td>\n","      <td>11012500</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2010-07-13</td>\n","      <td>3.478</td>\n","      <td>3.728</td>\n","      <td>3.380</td>\n","      <td>3.628</td>\n","      <td>3.628</td>\n","      <td>13400500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Date   Open   High    Low  Close  Adj Close    Volume\n","0 2010-06-29  3.800  5.000  3.508  4.778      4.778  93831500\n","1 2010-06-30  5.158  6.084  4.660  4.766      4.766  85935500\n","2 2010-07-01  5.000  5.184  4.054  4.392      4.392  41094000\n","3 2010-07-02  4.600  4.620  3.742  3.840      3.840  25699000\n","4 2010-07-06  4.000  4.000  3.166  3.222      3.222  34334500\n","5 2010-07-07  3.280  3.326  2.996  3.160      3.160  34608500\n","6 2010-07-08  3.228  3.504  3.114  3.492      3.492  38557000\n","7 2010-07-09  3.516  3.580  3.310  3.480      3.480  20253000\n","8 2010-07-12  3.590  3.614  3.400  3.410      3.410  11012500\n","9 2010-07-13  3.478  3.728  3.380  3.628      3.628  13400500"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"4U5EereYNkVs"},"source":["# Labelling same day and previous day"]},{"cell_type":"code","metadata":{"id":"bjSC6wZ0NfTH","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"c4c91262-d411-4bf2-d16f-748d3e0adbc7"},"source":["tweet_dates = (df_st1['Date'].astype(str)).tolist() #len(tweet_dates)\n","stock_dates = (df_prices['Date'].astype(str)).tolist() #len(stock_dates)\n","tweet_time = df_st1['Time'].tolist() \n","\n","print(len(tweet_dates))\n","print(len(stock_dates))\n","print(len(tweet_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1799486\n","2530\n","1799486\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KVmMMQ_WsTsz"},"source":["def get_label(ch):\n","  if ch>0.5:\n","    return 1\n","  elif ch<-0.5:\n","    return -1\n","  else:\n","    return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VTrB6IiQsUas"},"source":["date_label = []\n","dates_index = []\n","date_label_same=[]\n","stock_close = df_prices['Close']\n","stock_open = df_prices['Open']\n","for i in range(1,len(stock_close)):\n","  label=99\n","  # daydiff = datetime.strptime(datetime.strftime(stock_dates[i], \"%Y-%m-%d\"), \"%Y-%m-%d\") - datetime.strptime(datetime.strftime(stock_dates[i-1], \"%Y-%m-%d\"),\"%Y-%m-%d\")\n","  daydiff = datetime.strptime(stock_dates[i], \"%Y-%m-%d\") - datetime.strptime(stock_dates[i-1], \"%Y-%m-%d\")\n","  if daydiff.days == 1:\n","    change = ((stock_close[i]-stock_close[i-1])/stock_close[i-1])*100\n","    change_same = ((stock_close[i]-stock_open[i])/stock_open[i])*100\n","    if change>0.5:\n","      label = 1\n","    elif change<-0.5:\n","      label = -1\n","    else:\n","      label = 0\n","    label_same = get_label(change_same)\n","    date_label_same.append((datetime.strptime(stock_dates[i], \"%Y-%m-%d\"), change_same,label_same))\n","    date_label.append((datetime.strptime(stock_dates[i], \"%Y-%m-%d\"), change,label))\n","    dates_index.append(datetime.strptime(stock_dates[i], \"%Y-%m-%d\"))\n","  else:\n","    daysgap = daydiff.days\n","    daysadd = 1\n","    change_l_same = ((stock_close[i]-stock_open[i])/stock_open[i])*100\n","    change_l = ((stock_close[i]-stock_close[i-1])/stock_close[i-1])*100\n","    while daysgap >1:\n","      # gapDate = datetime.strptime(datetime.strftime(stock_dates[i-1], \"%Y-%m-%d\"), \"%Y-%m-%d\") + timedelta(days=daysadd)\n","      gapDate = datetime.strptime(stock_dates[i-1], \"%Y-%m-%d\") + timedelta(days=daysadd)\n","      change_g_mean_same = (change_l_same + date_label_same[-1][1])/2\n","      change_g_mean = (change_l + date_label[-1][1])/2\n","      if change_g_mean>0.5:\n","        label = 1\n","      elif change_g_mean<-0.5:\n","        label = -1\n","      else:\n","        label = 0\n","      label_same = get_label(change_g_mean_same)\n","      date_label_same.append((datetime.strptime(datetime.strftime(gapDate, \"%Y-%m-%d\"),\"%Y-%m-%d\"), change_g_mean_same,label_same))\n","      date_label.append((datetime.strptime(datetime.strftime(gapDate, \"%Y-%m-%d\"),\"%Y-%m-%d\"), change_g_mean,label))\n","      dates_index.append(datetime.strptime(datetime.strftime(gapDate, \"%Y-%m-%d\"),\"%Y-%m-%d\"))\n","      daysgap = daysgap - 1\n","      daysadd = daysadd + 1\n","    date_label_same.append((datetime.strptime(stock_dates[i], \"%Y-%m-%d\"), change_l_same,get_label(change_l_same)))\n","    label = get_label(change_l)\n","    date_label.append((datetime.strptime(stock_dates[i], \"%Y-%m-%d\"), change_l,label))\n","    date_check = datetime.strptime(stock_dates[i], \"%Y-%m-%d\")\n","\n","    dates_index.append(date_check)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9kBCuU8sadM"},"source":["polarity = []\n","change = []\n","polarity_same = []\n","change_same = []\n","ff=0\n","for index, row in df_st1.iterrows():\n","  \n","  d1 = datetime.strftime(row['Date'], \"%Y-%m-%d\")   #2020-07-21T21:37:30Z\t\n","  d2 = datetime.strptime(d1, \"%Y-%m-%d\")\n","  \n","  if d2 not in dates_index:\n","    change.append(-99)\n","    polarity.append(-99)\n","    polarity_same.append(-99)\n","    change_same.append(-99)\n","    continue\n","  d_index = dates_index.index(d2)\n","  polarity_same.append(date_label_same[d_index][2])\n","  polarity.append(date_label[d_index][2])\n","  change.append(date_label[d_index][1])\n","# df_st1['change'] = change\n","# df_st2 = df_st1.copy()\n","df_st1['label_previous'] = polarity\n","df_st1['label_same'] = polarity_same"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zCs8Q6r1ILSS","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"db8e8080-3d55-4db2-c867-656bf93beaf7"},"source":["print(dates_index[:100])\n","##"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[datetime.datetime(2010, 6, 30, 0, 0), datetime.datetime(2010, 7, 1, 0, 0), datetime.datetime(2010, 7, 2, 0, 0), datetime.datetime(2010, 7, 3, 0, 0), datetime.datetime(2010, 7, 4, 0, 0), datetime.datetime(2010, 7, 5, 0, 0), datetime.datetime(2010, 7, 6, 0, 0), datetime.datetime(2010, 7, 7, 0, 0), datetime.datetime(2010, 7, 8, 0, 0), datetime.datetime(2010, 7, 9, 0, 0), datetime.datetime(2010, 7, 10, 0, 0), datetime.datetime(2010, 7, 11, 0, 0), datetime.datetime(2010, 7, 12, 0, 0), datetime.datetime(2010, 7, 13, 0, 0), datetime.datetime(2010, 7, 14, 0, 0), datetime.datetime(2010, 7, 15, 0, 0), datetime.datetime(2010, 7, 16, 0, 0), datetime.datetime(2010, 7, 17, 0, 0), datetime.datetime(2010, 7, 18, 0, 0), datetime.datetime(2010, 7, 19, 0, 0), datetime.datetime(2010, 7, 20, 0, 0), datetime.datetime(2010, 7, 21, 0, 0), datetime.datetime(2010, 7, 22, 0, 0), datetime.datetime(2010, 7, 23, 0, 0), datetime.datetime(2010, 7, 24, 0, 0), datetime.datetime(2010, 7, 25, 0, 0), datetime.datetime(2010, 7, 26, 0, 0), datetime.datetime(2010, 7, 27, 0, 0), datetime.datetime(2010, 7, 28, 0, 0), datetime.datetime(2010, 7, 29, 0, 0), datetime.datetime(2010, 7, 30, 0, 0), datetime.datetime(2010, 7, 31, 0, 0), datetime.datetime(2010, 8, 1, 0, 0), datetime.datetime(2010, 8, 2, 0, 0), datetime.datetime(2010, 8, 3, 0, 0), datetime.datetime(2010, 8, 4, 0, 0), datetime.datetime(2010, 8, 5, 0, 0), datetime.datetime(2010, 8, 6, 0, 0), datetime.datetime(2010, 8, 7, 0, 0), datetime.datetime(2010, 8, 8, 0, 0), datetime.datetime(2010, 8, 9, 0, 0), datetime.datetime(2010, 8, 10, 0, 0), datetime.datetime(2010, 8, 11, 0, 0), datetime.datetime(2010, 8, 12, 0, 0), datetime.datetime(2010, 8, 13, 0, 0), datetime.datetime(2010, 8, 14, 0, 0), datetime.datetime(2010, 8, 15, 0, 0), datetime.datetime(2010, 8, 16, 0, 0), datetime.datetime(2010, 8, 17, 0, 0), datetime.datetime(2010, 8, 18, 0, 0), datetime.datetime(2010, 8, 19, 0, 0), datetime.datetime(2010, 8, 20, 0, 0), datetime.datetime(2010, 8, 21, 0, 0), datetime.datetime(2010, 8, 22, 0, 0), datetime.datetime(2010, 8, 23, 0, 0), datetime.datetime(2010, 8, 24, 0, 0), datetime.datetime(2010, 8, 25, 0, 0), datetime.datetime(2010, 8, 26, 0, 0), datetime.datetime(2010, 8, 27, 0, 0), datetime.datetime(2010, 8, 28, 0, 0), datetime.datetime(2010, 8, 29, 0, 0), datetime.datetime(2010, 8, 30, 0, 0), datetime.datetime(2010, 8, 31, 0, 0), datetime.datetime(2010, 9, 1, 0, 0), datetime.datetime(2010, 9, 2, 0, 0), datetime.datetime(2010, 9, 3, 0, 0), datetime.datetime(2010, 9, 4, 0, 0), datetime.datetime(2010, 9, 5, 0, 0), datetime.datetime(2010, 9, 6, 0, 0), datetime.datetime(2010, 9, 7, 0, 0), datetime.datetime(2010, 9, 8, 0, 0), datetime.datetime(2010, 9, 9, 0, 0), datetime.datetime(2010, 9, 10, 0, 0), datetime.datetime(2010, 9, 11, 0, 0), datetime.datetime(2010, 9, 12, 0, 0), datetime.datetime(2010, 9, 13, 0, 0), datetime.datetime(2010, 9, 14, 0, 0), datetime.datetime(2010, 9, 15, 0, 0), datetime.datetime(2010, 9, 16, 0, 0), datetime.datetime(2010, 9, 17, 0, 0), datetime.datetime(2010, 9, 18, 0, 0), datetime.datetime(2010, 9, 19, 0, 0), datetime.datetime(2010, 9, 20, 0, 0), datetime.datetime(2010, 9, 21, 0, 0), datetime.datetime(2010, 9, 22, 0, 0), datetime.datetime(2010, 9, 23, 0, 0), datetime.datetime(2010, 9, 24, 0, 0), datetime.datetime(2010, 9, 25, 0, 0), datetime.datetime(2010, 9, 26, 0, 0), datetime.datetime(2010, 9, 27, 0, 0), datetime.datetime(2010, 9, 28, 0, 0), datetime.datetime(2010, 9, 29, 0, 0), datetime.datetime(2010, 9, 30, 0, 0), datetime.datetime(2010, 10, 1, 0, 0), datetime.datetime(2010, 10, 2, 0, 0), datetime.datetime(2010, 10, 3, 0, 0), datetime.datetime(2010, 10, 4, 0, 0), datetime.datetime(2010, 10, 5, 0, 0), datetime.datetime(2010, 10, 6, 0, 0), datetime.datetime(2010, 10, 7, 0, 0)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B8G7WU8SD08e"},"source":["# Preprocess data"]},{"cell_type":"code","metadata":{"id":"esFC7WFwe5tR"},"source":["# fill nan values in file with '0'\n","df_st1.isna().values.any()\n","df_st1['message'] = df_st1['message'].fillna('0')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z70r1eYrnoB_","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"6209d215-e13b-44f6-d813-e758b1bb1e68"},"source":["df_st1['message'] = df_st1['message'].str.lower()\n","message = df_st1['message'].tolist()\n","\n","print(message[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['$ecor i&#39;m adding here. covid play with big bounce potential/aftershock, lots of news on the reg and great support at current levels. \\n\\nthis one will be as good as my $htbx call and my $ccl call from this week and better than my $tsla call. mark.this.post', '$tsla trash', '$tsla https://www.tesmanian.com/blogs/tesmanian-blog/tesla-entering-greek-market 🏎🚀', '$tsla what&#39;s happening here? considerin selling out tomorrow! convince me otherwise', '$bb https://publishing.ninja/v4/page/10630/414/270/1  $tsla', '$tsla it&#39;s not gonna make earnings. this stock is screwed.', '$vuzi $tsla $nio $himx', '$tsla https://finance.yahoo.com/news/york-invest-750-million-expand-220748873.html', '$tsla look whose coming for you cybertruck', '$tsla by tomorrow $nflx  will be up and this will be finding another reason for hanging out at 1500.00\\n\\noh buy cramer is promoting suzy ormond. go short hair']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C65MA9lJnwEv"},"source":["def remove_stopwords(msg):\n","    filtered_sentence = [w for w in msg_tokens if not w in stop_words]\n","    return filtered_sentence\n","\n","def remove_punctuation_re(x):\n","    x = ' '.join(re.sub(\"https?://\\S+\",\"\",x).split())     #Removing URLs\n","\n","    x = ' '.join(re.sub(\"^@\\S+|\\s@\\S+\",\"\",x).split())     #Removing Mentions\n","\n","    # x = ' '.join(re.sub(r'[^$\\w\\s]',\" \",x).split())\n","    x = ' '.join(re.sub(r'[^\\w\\s]',\" \",x).split())        #Removes Hashtags\n","\n","    x = ' '.join(re.sub(r'_',\" \",x).split())              #Removing _ from emojis text\n","\n","    return x\n","\n","# replace repeating letter\n","def rpt_replace(match):\n","    # print(match.group(1))\n","    return match.group(1)+match.group(1)\n","\n","# substitute original word with replaced word, if any\n","def processRepeatings(data):\n","    re_t= re.sub(message_rpt, rpt_replace, data )\n","    # print(re_t)\n","    return re_t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_3YWRwzLBGs1","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"476d8fa0-26ad-4e35-d896-139b3c1c8a52"},"source":["stop_words = sw.words(\"english\")\n","tweet_tokenizer = TweetTokenizer()\n","detokenizer = TreebankWordDetokenizer()\n","# message_p = []\n","\n","# for repeating characters in words\n","message_rpt = re.compile(r\"(.)\\1{2,}\", re.IGNORECASE)\n","\n","# segmenter using the word statistics from Twitter\n","seg_tw = Segmenter(corpus=\"twitter\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading twitter - 1grams ...\n","Reading twitter - 2grams ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4LRFAxgcn_fi","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"2ce33661-0d2d-4612-98af-7b97e7826bc6"},"source":["message_p = []\n","for msg in message:\n","\n","    if msg == '0': #nan replaced by '0'\n","      message_p.append('-1')\n","\n","    else:\n","      # remove emojis\n","      msg = emoji.demojize(msg)\n","\n","      # fix contractions\n","      msg = contractions.fix(msg)\n","\n","      # remove punctuations\n","      msg = remove_punctuation_re(msg) \n","\n","      #tokenize\n","      msg_tokens = tweet_tokenizer.tokenize(msg)\n","\n","      #For Hashtags elongated words using Word segmenter\n","      message_seg = []\n","      for w in msg_tokens:\n","        if len(w)>=300:\n","          w=w[:100]\n","          print(w)\n","        message_seg.append(seg_tw.segment(w))\n","\n","      # remove stopwords\n","      msg = remove_stopwords(message_seg)\n","\n","      if 'rt' in msg:\n","        # remove retweets\n","        message_p.append('-1')\n","      else: \n","        # detokenize\n","        msg = detokenizer.detokenize(msg)\n","\n","        # removing repeating characters like hurrrryyyyyy-- worrks on tokenized list\n","        msg = processRepeatings(msg)\n","\n","        message_p.append(msg)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["gooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n","gooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ixYHS-jyxI3D","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d4108dca-f3f5-4eca-eab1-3f813bea5bf7"},"source":["print(len('beeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pXWjHAcQoIEh","colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"b2bbe854-40d1-4b0a-fa75-cd722ecdaf65"},"source":["message_p[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ecor 39 adding covid play big bounce potential aftershock lots news reg great support current levels one good htbx call ccl call week better tsla call mark post',\n"," 'tsla trash',\n"," 'tsla racing car rocket',\n"," 'tsla 39 happening considerin selling tomorrow convince otherwise',\n"," 'bb tsla',\n"," 'tsla 39 going make earnings stock screwed',\n"," 'vuzi tsla nio himx',\n"," 'tsla',\n"," 'tsla look whose coming cybertruck',\n"," 'tsla tomorrow nflx finding another reason hanging 1500 00 oh buy cramer promoting suzy ormond go short hair']"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"KkSpMpJWAG4u","colab":{"base_uri":"https://localhost:8080/","height":658},"outputId":"f226f431-471a-4998-b9c8-5186243e9d11"},"source":["df_st1['message'] = message_p\n","df_st1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>symbol</th>\n","      <th>message</th>\n","      <th>datetime</th>\n","      <th>user</th>\n","      <th>message_id</th>\n","      <th>Date</th>\n","      <th>Time</th>\n","      <th>label_previous</th>\n","      <th>label_same</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TSLA</td>\n","      <td>ecor 39 adding covid play big bounce potential...</td>\n","      <td>2020-07-16 23:08:58</td>\n","      <td>1659003</td>\n","      <td>228472656</td>\n","      <td>2020-07-16</td>\n","      <td>23:08:58</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TSLA</td>\n","      <td>tsla trash</td>\n","      <td>2020-07-16 23:08:47</td>\n","      <td>3796654</td>\n","      <td>228472618</td>\n","      <td>2020-07-16</td>\n","      <td>23:08:47</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TSLA</td>\n","      <td>tsla racing car rocket</td>\n","      <td>2020-07-16 23:06:01</td>\n","      <td>335497</td>\n","      <td>228472036</td>\n","      <td>2020-07-16</td>\n","      <td>23:06:01</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TSLA</td>\n","      <td>tsla 39 happening considerin selling tomorrow ...</td>\n","      <td>2020-07-16 23:04:50</td>\n","      <td>3572445</td>\n","      <td>228471810</td>\n","      <td>2020-07-16</td>\n","      <td>23:04:50</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TSLA</td>\n","      <td>bb tsla</td>\n","      <td>2020-07-16 23:03:55</td>\n","      <td>1711636</td>\n","      <td>228471610</td>\n","      <td>2020-07-16</td>\n","      <td>23:03:55</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1799481</th>\n","      <td>TSLA</td>\n","      <td>think starts trading tomorrow tsla</td>\n","      <td>2010-06-29 00:46:52</td>\n","      <td>27</td>\n","      <td>1540976</td>\n","      <td>2010-06-29</td>\n","      <td>00:46:52</td>\n","      <td>-99</td>\n","      <td>-99</td>\n","    </tr>\n","    <tr>\n","      <th>1799482</th>\n","      <td>TSLA</td>\n","      <td>congrats tesla tsla going public today beginni...</td>\n","      <td>2010-06-29 00:42:24</td>\n","      <td>5</td>\n","      <td>1540973</td>\n","      <td>2010-06-29</td>\n","      <td>00:42:24</td>\n","      <td>-99</td>\n","      <td>-99</td>\n","    </tr>\n","    <tr>\n","      <th>1799483</th>\n","      <td>TSLA</td>\n","      <td>sat tsla know similar go kart</td>\n","      <td>2010-06-29 00:39:41</td>\n","      <td>289</td>\n","      <td>1540967</td>\n","      <td>2010-06-29</td>\n","      <td>00:39:41</td>\n","      <td>-99</td>\n","      <td>-99</td>\n","    </tr>\n","    <tr>\n","      <th>1799484</th>\n","      <td>TSLA</td>\n","      <td>-1</td>\n","      <td>2010-06-28 20:46:15</td>\n","      <td>27</td>\n","      <td>1540535</td>\n","      <td>2010-06-28</td>\n","      <td>20:46:15</td>\n","      <td>-99</td>\n","      <td>-99</td>\n","    </tr>\n","    <tr>\n","      <th>1799485</th>\n","      <td>TSLA</td>\n","      <td>new issue tesla motors stream live stocktwits ...</td>\n","      <td>2010-06-28 20:40:16</td>\n","      <td>27</td>\n","      <td>1540514</td>\n","      <td>2010-06-28</td>\n","      <td>20:40:16</td>\n","      <td>-99</td>\n","      <td>-99</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1799486 rows × 9 columns</p>\n","</div>"],"text/plain":["        symbol  ... label_same\n","0         TSLA  ...          1\n","1         TSLA  ...          1\n","2         TSLA  ...          1\n","3         TSLA  ...          1\n","4         TSLA  ...          1\n","...        ...  ...        ...\n","1799481   TSLA  ...        -99\n","1799482   TSLA  ...        -99\n","1799483   TSLA  ...        -99\n","1799484   TSLA  ...        -99\n","1799485   TSLA  ...        -99\n","\n","[1799486 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"uwzRoocCrMBC"},"source":["#Count, drop retweets and -99"]},{"cell_type":"code","metadata":{"id":"0b6qD-gHSaa7","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"4b4cace8-def3-4bae-e6a4-ba04774ac55f"},"source":["df_st1['label_same'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-1     784961\n"," 1     747629\n"," 0     266784\n","-99       112\n","Name: label_same, dtype: int64"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"mXdW9Wu7Sh3f","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"3655b213-7da5-49ae-a3af-3ec9e6096530"},"source":["df_st1['label_previous'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[" 1     841968\n","-1     728044\n"," 0     229362\n","-99       112\n","Name: label_previous, dtype: int64"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"3DraQK_uDcBU","colab":{"base_uri":"https://localhost:8080/","height":675},"outputId":"51f61496-5625-40a7-8b08-8de8d4880b7c"},"source":["# Drop Retweets\n","df_st1.drop(df_st1[df_st1['message'] == '-1'].index, inplace = True) \n","df_st1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>symbol</th>\n","      <th>message</th>\n","      <th>datetime</th>\n","      <th>user</th>\n","      <th>message_id</th>\n","      <th>Date</th>\n","      <th>Time</th>\n","      <th>label_previous</th>\n","      <th>label_same</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TSLA</td>\n","      <td>ecor 39 adding covid play big bounce potential...</td>\n","      <td>2020-07-16 23:08:58</td>\n","      <td>1659003</td>\n","      <td>228472656</td>\n","      <td>2020-07-16</td>\n","      <td>23:08:58</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TSLA</td>\n","      <td>tsla trash</td>\n","      <td>2020-07-16 23:08:47</td>\n","      <td>3796654</td>\n","      <td>228472618</td>\n","      <td>2020-07-16</td>\n","      <td>23:08:47</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TSLA</td>\n","      <td>tsla racing car rocket</td>\n","      <td>2020-07-16 23:06:01</td>\n","      <td>335497</td>\n","      <td>228472036</td>\n","      <td>2020-07-16</td>\n","      <td>23:06:01</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TSLA</td>\n","      <td>tsla 39 happening considerin selling tomorrow ...</td>\n","      <td>2020-07-16 23:04:50</td>\n","      <td>3572445</td>\n","      <td>228471810</td>\n","      <td>2020-07-16</td>\n","      <td>23:04:50</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TSLA</td>\n","      <td>bb tsla</td>\n","      <td>2020-07-16 23:03:55</td>\n","      <td>1711636</td>\n","      <td>228471610</td>\n","      <td>2020-07-16</td>\n","      <td>23:03:55</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1799480</th>\n","      <td>TSLA</td>\n","      <td>guess 39 roll dice tsla tomorrow 39 think 1 39...</td>\n","      <td>2010-06-29 00:48:45</td>\n","      <td>11104</td>\n","      <td>1540981</td>\n","      <td>2010-06-29</td>\n","      <td>00:48:45</td>\n","      <td>-99</td>\n","      <td>-99</td>\n","    </tr>\n","    <tr>\n","      <th>1799481</th>\n","      <td>TSLA</td>\n","      <td>think starts trading tomorrow tsla</td>\n","      <td>2010-06-29 00:46:52</td>\n","      <td>27</td>\n","      <td>1540976</td>\n","      <td>2010-06-29</td>\n","      <td>00:46:52</td>\n","      <td>-99</td>\n","      <td>-99</td>\n","    </tr>\n","    <tr>\n","      <th>1799482</th>\n","      <td>TSLA</td>\n","      <td>congrats tesla tsla going public today beginni...</td>\n","      <td>2010-06-29 00:42:24</td>\n","      <td>5</td>\n","      <td>1540973</td>\n","      <td>2010-06-29</td>\n","      <td>00:42:24</td>\n","      <td>-99</td>\n","      <td>-99</td>\n","    </tr>\n","    <tr>\n","      <th>1799483</th>\n","      <td>TSLA</td>\n","      <td>sat tsla know similar go kart</td>\n","      <td>2010-06-29 00:39:41</td>\n","      <td>289</td>\n","      <td>1540967</td>\n","      <td>2010-06-29</td>\n","      <td>00:39:41</td>\n","      <td>-99</td>\n","      <td>-99</td>\n","    </tr>\n","    <tr>\n","      <th>1799485</th>\n","      <td>TSLA</td>\n","      <td>new issue tesla motors stream live stocktwits ...</td>\n","      <td>2010-06-28 20:40:16</td>\n","      <td>27</td>\n","      <td>1540514</td>\n","      <td>2010-06-28</td>\n","      <td>20:40:16</td>\n","      <td>-99</td>\n","      <td>-99</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1798633 rows × 9 columns</p>\n","</div>"],"text/plain":["        symbol  ... label_same\n","0         TSLA  ...          1\n","1         TSLA  ...          1\n","2         TSLA  ...          1\n","3         TSLA  ...          1\n","4         TSLA  ...          1\n","...        ...  ...        ...\n","1799480   TSLA  ...        -99\n","1799481   TSLA  ...        -99\n","1799482   TSLA  ...        -99\n","1799483   TSLA  ...        -99\n","1799485   TSLA  ...        -99\n","\n","[1798633 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"iKio6CyuSwnd","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"b2db9ee6-9426-4805-97ce-7c419857fbe3"},"source":["df_st1['label_same'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-1     784584\n"," 1     747268\n"," 0     266682\n","-99        99\n","Name: label_same, dtype: int64"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"5PiPeJ0wSxN_","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"c0b90718-2aa6-488f-c21e-dd482cca45d0"},"source":["df_st1['label_previous'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[" 1     841562\n","-1     727708\n"," 0     229264\n","-99        99\n","Name: label_previous, dtype: int64"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"klceiHilQeDl"},"source":["df_st2 = df_st1.copy()\n","df_st1.drop(columns=['label_same'], axis=1, inplace=True)\n","df_st2.drop(columns=['label_previous'], axis=1, inplace=True)\n","df_st2.rename(columns = {'label_same':'label'}, inplace = True) \n","df_st1.rename(columns = {'label_previous':'label'}, inplace = True) \n","\n","# Drop polarity -99\n","df_st1.drop(df_st1[df_st1['label'] == -99].index, inplace = True) \n","df_st2.drop(df_st2[df_st2['label'] == -99].index, inplace = True) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-E02gUwGNzCG"},"source":["# Saving the CSV files"]},{"cell_type":"code","metadata":{"id":"r4B8AEJUOEIB"},"source":["df_st1.to_csv(PATH2, header=True, index=False, encoding='utf_8')\n","df_st2.to_csv(PATH, header=True, index=False, encoding='utf_8')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n4yjzBW1NSCy"},"source":["# Extra(Same day logic)--Do not run"]},{"cell_type":"code","metadata":{"id":"mIUREs1AiUDI"},"source":["# ####Comparing Close price and Open Price of Same day (close-open)/open\n","# price_change = []\n","# for i in range(len(df_prices)):\n","#   change = ((df_prices.iloc[i][4]-df_prices.iloc[i][1])/df_prices.iloc[i][1])*100\n","#   price_change.append(change)\n","# df_prices['PriceChange'] = price_change\n","# df_prices.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUk4qemapc7l"},"source":["# tweet_dates = (df_st1['Date'].astype(str)).tolist() #len(tweet_dates)\n","# stock_dates = (df_prices['Date'].astype(str)).tolist() #len(stock_dates)\n","# percentage_change = df_prices['PriceChange'].tolist() #len(percentage_change)\n","# tweet_time = df_st1['Time'].tolist() \n","# # percentage_date = (df_prices['Date'].astype(str)).tolist() #len(percentage_date)\n","# print(len(tweet_dates))\n","# print(len(stock_dates))\n","# print(len(percentage_change))\n","# print(len(tweet_time))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9j3-_J2T8hLl"},"source":["# check =1\n","# for da in tweet_dates:\n","#   # if check == 1:\n","#   #   if da not in stock_dates:\n","#   #     continue\n","#   # else:\n","#   #   check = 2\n","#   if da not in stock_dates:\n","#     flag1 = False\n","#     temp1_da = da\n","#     # print(temp1_da)\n","#     while flag1 == False:\n","#       temp1_da = datetime.strptime(temp1_da, \"%Y-%m-%d\") + timedelta(days=-1)\n","#       temp1_da = datetime.strftime(temp1_da, \"%Y-%m-%d\")\n","#       if temp1_da not in stock_dates:\n","#         continue\n","#       else:\n","#         flag1=True\n","#         flag2 = False\n","#         temp2_da = da\n","#         while flag2 == False:\n","#           temp2_da = datetime.strptime(temp2_da, \"%Y-%m-%d\") + timedelta(days=1)\n","#           # print('check3', temp2_da)\n","#           temp2_da = datetime.strftime(temp2_da, \"%Y-%m-%d\")\n","#           # print('check4', temp2_da)\n","#           if temp2_da not in stock_dates:\n","#             # print('check3')\n","#             continue\n","#           else:\n","#             flag2= True\n","#             day_before_change = 0\n","#             day_after_change = 0\n","#             count = 0\n","#             for dat, per_change in zip(stock_dates,percentage_change):\n","#               count\n","#               if temp1_da == dat:\n","#                 day_before_change = per_change\n","#                 count = count +1\n","#               elif temp2_da == dat:\n","#                 day_after_change = per_change\n","#                 count = count +1\n","#               if count == 2:\n","                \n","#                 mean_change = (day_before_change+day_after_change)/2\n","#                 # print(da,mean_change)\n","#                 stock_dates.append(da)\n","#                 percentage_change.append(mean_change)\n","#                 break\n","#               else:\n","#                 continue\n","# print(len(percentage_change))\n","# print(len(stock_dates))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iXRGYIOnHhtB"},"source":["# print(len(percentage_change))\n","# print(len(stock_dates))\n","# print(len(tweet_dates))\n","# a = set(stock_dates) \n","# print(len(a))\n","# b = set(tweet_dates) \n","# print(len(b))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXW9RS6w6lez"},"source":["# tweet_polarity = []\n","# # stock_change = []\n","# # for date,pc in zip(stock_dates,percentage_change): \n","# #   stock_change.append((date,pc))    #len(stock_change)\n","# msg_tweet = df_st1['message'].tolist()  #len(msg_tweet)\n","# # msg_grouped = []\n","# # for date,msg in zip(tweet_dates,msg_tweet): #len(msg_grouped)\n","# #   msg_grouped.append((date,msg))\n","\n","# counter = 0\n","# for date, pc in zip(stock_dates,percentage_change):\n","#   for datetweet in tweet_dates:\n","\n","#     if date == datetweet:\n","#       if pc > 0.5:\n","#         tweet_polarity.append(1)\n","#       elif pc < -0.5:\n","#         tweet_polarity.append(-1)\n","#       else:\n","#         tweet_polarity.append( 0)\n","\n","# print(len(tweet_polarity))\n","# print(len(tweet_dates))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xbXTW27jv4mS"},"source":["# dict_sameday = {'date': tweet_dates,'message': msg_tweet, 'label': tweet_polarity, 'time': tweet_time}  \n","    \n","# df_labelled = pd.DataFrame(dict_sameday) "],"execution_count":null,"outputs":[]}]}