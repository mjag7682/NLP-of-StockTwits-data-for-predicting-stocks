{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinALBERT Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jKP2ARJ85wQp"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjag7682/CS9-1-NLP-for-Twitter-Data-for-predicting-stocks/blob/FinALBERT/FinALBERT_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64HBpBg3U_hx",
        "outputId": "cd6189cb-8dd9-4fae-df31-5bab267d2abd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "!pip install transformers\n",
        "!pip3 install albert-tensorflow\n",
        "!pip install torch\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=e660d257e555dfb2ca46c0fbcb2f07e411e156954d1e5fe2569e2863847ae25c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n",
            "Collecting albert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/1e/e776bb23e6f89a1f1d7d33b50d0bd9c2c7b24b39aa548f041827a9c00d73/albert_tensorflow-1.1-py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from albert-tensorflow) (1.15.0)\n",
            "Installing collected packages: albert-tensorflow\n",
            "Successfully installed albert-tensorflow-1.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkYt-bT5VQTE",
        "outputId": "52ffd11f-aa85-4bb7-ca4e-1a653340c102",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF2lpQxZVREl",
        "outputId": "c84767c7-d6a2-4903-fe44-0c6e383a14c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvZdQdeaVSWr",
        "outputId": "63809ae8-1942-4bea-bf30-92d38d23710d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCnmgtkSadRx",
        "outputId": "659a7287-cfae-4370-d9e1-281547637287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/Data/Combined_percentage_2.2.csv', sep=',')\n",
        "df = df[df['message'].notna()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp7iWPeIavCU",
        "outputId": "27ce3230-e5fa-4529-982e-d5763161818c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>message</th>\n",
              "      <th>datetime</th>\n",
              "      <th>user</th>\n",
              "      <th>message_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>peak profit last 6 expired option alerts aapl ...</td>\n",
              "      <td>2020-07-19 09:49:35</td>\n",
              "      <td>1442893</td>\n",
              "      <td>229008387</td>\n",
              "      <td>2020-07-19</td>\n",
              "      <td>09:49:35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl jul 17 382 50 calls option volume 144 44 ...</td>\n",
              "      <td>2020-07-19 09:47:26</td>\n",
              "      <td>1442893</td>\n",
              "      <td>229008357</td>\n",
              "      <td>2020-07-19</td>\n",
              "      <td>09:47:26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>tsla market true bubble territory profitable c...</td>\n",
              "      <td>2020-07-19 09:01:25</td>\n",
              "      <td>1115913</td>\n",
              "      <td>229007569</td>\n",
              "      <td>2020-07-19</td>\n",
              "      <td>09:01:25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl analyzed 26 analysts buy consensus 86 ana...</td>\n",
              "      <td>2020-07-19 08:13:00</td>\n",
              "      <td>47688</td>\n",
              "      <td>229006733</td>\n",
              "      <td>2020-07-19</td>\n",
              "      <td>08:13:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl new article dogs dow august 4 adopt ignore</td>\n",
              "      <td>2020-07-19 07:54:05</td>\n",
              "      <td>1555408</td>\n",
              "      <td>229006403</td>\n",
              "      <td>2020-07-19</td>\n",
              "      <td>07:54:05</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6450984</th>\n",
              "      <td>WMT</td>\n",
              "      <td>added oct 30 puts vz</td>\n",
              "      <td>2009-09-17 15:06:09</td>\n",
              "      <td>564</td>\n",
              "      <td>578933</td>\n",
              "      <td>2009-09-17</td>\n",
              "      <td>15:06:09</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6450985</th>\n",
              "      <td>WMT</td>\n",
              "      <td>palm pre could use deal vz holidays 09 perhaps</td>\n",
              "      <td>2009-09-17 14:56:06</td>\n",
              "      <td>256</td>\n",
              "      <td>578846</td>\n",
              "      <td>2009-09-17</td>\n",
              "      <td>14:56:06</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6450986</th>\n",
              "      <td>WMT</td>\n",
              "      <td>bought little vz 29 99</td>\n",
              "      <td>2009-09-17 14:45:21</td>\n",
              "      <td>20</td>\n",
              "      <td>578746</td>\n",
              "      <td>2009-09-17</td>\n",
              "      <td>14:45:21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6450987</th>\n",
              "      <td>WMT</td>\n",
              "      <td>thnx agreed like palm pre needs get 39 conside...</td>\n",
              "      <td>2009-09-15 14:08:45</td>\n",
              "      <td>409</td>\n",
              "      <td>568971</td>\n",
              "      <td>2009-09-15</td>\n",
              "      <td>14:08:45</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6450988</th>\n",
              "      <td>WMT</td>\n",
              "      <td>good hopefully vz make happen sooner rather la...</td>\n",
              "      <td>2009-09-11 13:34:04</td>\n",
              "      <td>409</td>\n",
              "      <td>559954</td>\n",
              "      <td>2009-09-11</td>\n",
              "      <td>13:34:04</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6449174 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        symbol  ... label\n",
              "0         AAPL  ...     1\n",
              "1         AAPL  ...     1\n",
              "2         AAPL  ...     1\n",
              "3         AAPL  ...     1\n",
              "4         AAPL  ...     1\n",
              "...        ...  ...   ...\n",
              "6450984    WMT  ...     0\n",
              "6450985    WMT  ...     0\n",
              "6450986    WMT  ...     0\n",
              "6450987    WMT  ...    -1\n",
              "6450988    WMT  ...    -1\n",
              "\n",
              "[6449174 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1wS5Rw_FXm6",
        "outputId": "9ac4f0d9-aecb-4eb0-bcb5-657bcfa00659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "# Uncomment for FB\n",
        "# FB_IPO = '2012-05-21'\n",
        "df.drop(df[df['Date'] < '2019-12-31'].index, inplace = True) \n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>message</th>\n",
              "      <th>datetime</th>\n",
              "      <th>user</th>\n",
              "      <th>message_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>peak profit last 6 expired option alerts aapl ...</td>\n",
              "      <td>2020-07-19 09:49:35</td>\n",
              "      <td>1442893</td>\n",
              "      <td>229008387</td>\n",
              "      <td>2020-07-19</td>\n",
              "      <td>09:49:35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl jul 17 382 50 calls option volume 144 44 ...</td>\n",
              "      <td>2020-07-19 09:47:26</td>\n",
              "      <td>1442893</td>\n",
              "      <td>229008357</td>\n",
              "      <td>2020-07-19</td>\n",
              "      <td>09:47:26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>tsla market true bubble territory profitable c...</td>\n",
              "      <td>2020-07-19 09:01:25</td>\n",
              "      <td>1115913</td>\n",
              "      <td>229007569</td>\n",
              "      <td>2020-07-19</td>\n",
              "      <td>09:01:25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl analyzed 26 analysts buy consensus 86 ana...</td>\n",
              "      <td>2020-07-19 08:13:00</td>\n",
              "      <td>47688</td>\n",
              "      <td>229006733</td>\n",
              "      <td>2020-07-19</td>\n",
              "      <td>08:13:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl new article dogs dow august 4 adopt ignore</td>\n",
              "      <td>2020-07-19 07:54:05</td>\n",
              "      <td>1555408</td>\n",
              "      <td>229006403</td>\n",
              "      <td>2020-07-19</td>\n",
              "      <td>07:54:05</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6437531</th>\n",
              "      <td>WMT</td>\n",
              "      <td>verizon vz business launches comeback coach</td>\n",
              "      <td>2020-07-20 13:51:05</td>\n",
              "      <td>1765977</td>\n",
              "      <td>229194849</td>\n",
              "      <td>2020-07-20</td>\n",
              "      <td>13:51:05</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6437532</th>\n",
              "      <td>WMT</td>\n",
              "      <td>vz verizon media enables grocery shopping emai...</td>\n",
              "      <td>2020-07-20 13:50:00</td>\n",
              "      <td>47688</td>\n",
              "      <td>229194314</td>\n",
              "      <td>2020-07-20</td>\n",
              "      <td>13:50:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6437533</th>\n",
              "      <td>WMT</td>\n",
              "      <td>vz new article verizon business launches comeb...</td>\n",
              "      <td>2020-07-20 13:45:56</td>\n",
              "      <td>1555408</td>\n",
              "      <td>229192509</td>\n",
              "      <td>2020-07-20</td>\n",
              "      <td>13:45:56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6437534</th>\n",
              "      <td>WMT</td>\n",
              "      <td>vz verizon business launches comeback coach</td>\n",
              "      <td>2020-07-20 13:33:55</td>\n",
              "      <td>253206</td>\n",
              "      <td>229187336</td>\n",
              "      <td>2020-07-20</td>\n",
              "      <td>13:33:55</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6437535</th>\n",
              "      <td>WMT</td>\n",
              "      <td>vz verizon business launches comeback coach</td>\n",
              "      <td>2020-07-20 13:30:55</td>\n",
              "      <td>2762379</td>\n",
              "      <td>229186313</td>\n",
              "      <td>2020-07-20</td>\n",
              "      <td>13:30:55</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1239679 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        symbol  ... label\n",
              "0         AAPL  ...     1\n",
              "1         AAPL  ...     1\n",
              "2         AAPL  ...     1\n",
              "3         AAPL  ...     1\n",
              "4         AAPL  ...     1\n",
              "...        ...  ...   ...\n",
              "6437531    WMT  ...     0\n",
              "6437532    WMT  ...     0\n",
              "6437533    WMT  ...     0\n",
              "6437534    WMT  ...     0\n",
              "6437535    WMT  ...     0\n",
              "\n",
              "[1239679 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "687_I0lVcEOw",
        "outputId": "d1d569b3-74bc-4540-8379-ce7d8cbcbf9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df[\"label\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    616875\n",
              "-1    454983\n",
              " 0    167821\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU07T36-FlMc"
      },
      "source": [
        "df = df.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4nshaKocG4E"
      },
      "source": [
        "df.drop(df[df['label'] == 0].index, inplace = True) \n",
        "df[\"label\"].replace({-1: 0}, inplace=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyQtCbQ3cIgi",
        "outputId": "24b7d11e-259e-4100-8319-85f3c606c1c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df[\"label\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    616875\n",
              "0    454983\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vR7aSSjF2rO",
        "outputId": "48514ffc-1b21-48de-e1bb-9eeaf93de120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>message</th>\n",
              "      <th>datetime</th>\n",
              "      <th>user</th>\n",
              "      <th>message_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62648</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>nflx red amzn aapl fb spy green earnings seaso...</td>\n",
              "      <td>2020-04-22 13:36:13</td>\n",
              "      <td>226994</td>\n",
              "      <td>207828255</td>\n",
              "      <td>2020-04-22</td>\n",
              "      <td>13:36:13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3611284</th>\n",
              "      <td>QQQ</td>\n",
              "      <td>spy iwm qq dia quot meet world 39 worst financ...</td>\n",
              "      <td>2020-03-10 18:34:38</td>\n",
              "      <td>673259</td>\n",
              "      <td>199402337</td>\n",
              "      <td>2020-03-10</td>\n",
              "      <td>18:34:38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2852618</th>\n",
              "      <td>NFLX</td>\n",
              "      <td>nflx take off rocket rocket rocket bye bears w...</td>\n",
              "      <td>2020-04-22 13:27:01</td>\n",
              "      <td>2917677</td>\n",
              "      <td>207825338</td>\n",
              "      <td>2020-04-22</td>\n",
              "      <td>13:27:01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290052</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>amzn currently trading near 52 week high good ...</td>\n",
              "      <td>2020-05-26 18:40:00</td>\n",
              "      <td>47688</td>\n",
              "      <td>215044213</td>\n",
              "      <td>2020-05-26</td>\n",
              "      <td>18:40:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4535492</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>amzn think reason something far sinister south...</td>\n",
              "      <td>2020-04-21 23:34:51</td>\n",
              "      <td>1900305</td>\n",
              "      <td>207748990</td>\n",
              "      <td>2020-04-21</td>\n",
              "      <td>23:34:51</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4625418</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>tsla massive massive growth ahead yes right li...</td>\n",
              "      <td>2020-03-11 16:04:49</td>\n",
              "      <td>1021809</td>\n",
              "      <td>199612325</td>\n",
              "      <td>2020-03-11</td>\n",
              "      <td>16:04:49</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1930206</th>\n",
              "      <td>DIA</td>\n",
              "      <td>09 23 06 angola pledge end opec cheating said ...</td>\n",
              "      <td>2020-07-03 13:23:10</td>\n",
              "      <td>3358599</td>\n",
              "      <td>225188297</td>\n",
              "      <td>2020-07-03</td>\n",
              "      <td>13:23:10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4710941</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>tsla tesla market cap 140bn projected 2020 sal...</td>\n",
              "      <td>2020-02-12 19:32:47</td>\n",
              "      <td>79156</td>\n",
              "      <td>194600992</td>\n",
              "      <td>2020-02-12</td>\n",
              "      <td>19:32:47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4466221</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>tsla 900 friday</td>\n",
              "      <td>2020-05-20 17:58:06</td>\n",
              "      <td>1922816</td>\n",
              "      <td>214013527</td>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>17:58:06</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98810</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>aapl looks like fed want care far announcement</td>\n",
              "      <td>2020-03-10 19:01:16</td>\n",
              "      <td>769857</td>\n",
              "      <td>199410689</td>\n",
              "      <td>2020-03-10</td>\n",
              "      <td>19:01:16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1071858 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        symbol  ... label\n",
              "62648     AAPL  ...     1\n",
              "3611284    QQQ  ...     1\n",
              "2852618   NFLX  ...     0\n",
              "1290052   AMZN  ...     0\n",
              "4535492   TSLA  ...     0\n",
              "...        ...  ...   ...\n",
              "4625418   TSLA  ...     0\n",
              "1930206    DIA  ...     1\n",
              "4710941   TSLA  ...     0\n",
              "4466221   TSLA  ...     1\n",
              "98810     AAPL  ...     1\n",
              "\n",
              "[1071858 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi5k3C79ariW"
      },
      "source": [
        "train_data = df[:1000000]\n",
        "test_data = df[1000001:1071858]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sACQ4D2vaqnV",
        "outputId": "19e1ece0-4096-4537-ba53-7313b7653b1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Number of training examples {}\".format(len(train_data)))\n",
        "# num_examples = 100000\n",
        "train = train_data.message.values\n",
        "labels = train_data.label.values\n",
        "# train = train_data[]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples 1000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi8LIFT4a5XF",
        "outputId": "ec97d8d7-a72c-4178-b102-addc72a2b7f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', train[10])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(train[10]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train[10])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  tsla einhorn loses\n",
            "Tokenized:  ['▁t', 's', 'la', '▁e', 'in', 'horn', '▁loses']\n",
            "Token IDs:  [104, 12, 5249, 180, 258, 6901, 3060]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKP2ARJ85wQp"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok7wL7Gyjshz"
      },
      "source": [
        "###Load Fine-tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70No9lqYTnxs",
        "outputId": "49fefb8b-e7a3-409e-ca17-8cc78eac7e05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import AlbertTokenizer\n",
        "from transformers.modeling_albert import AlbertModel, load_tf_weights_in_albert, AlbertPreTrainedModel\n",
        "from transformers import AlbertForSequenceClassification,AlbertConfig\n",
        "from transformers.tokenization_bert import BertTokenizer\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "VOCAB_FILE = \"/content/gdrive/My Drive/AGnewsmodel/30k-clean.model\" # This is the vocab file output from Build Vocab step\n",
        "CONFIG_FILE = \"/content/gdrive/My Drive/AGnewsmodel/config.json\"\n",
        "tokenizer = AlbertTokenizer(vocab_file=VOCAB_FILE)\n",
        "config = AlbertConfig.from_json_file(CONFIG_FILE)\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME_OR_PATH = '/content/gdrive/My Drive/AGnewsmodel/Fine-Tuned'\n",
        "model = AlbertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME_OR_PATH, num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlbertForSequenceClassification(\n",
              "  (albert): AlbertModel(\n",
              "    (embeddings): AlbertEmbeddings(\n",
              "      (word_embeddings): Embedding(20001, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0, inplace=False)\n",
              "    )\n",
              "    (encoder): AlbertTransformer(\n",
              "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
              "      (albert_layer_groups): ModuleList(\n",
              "        (0): AlbertLayerGroup(\n",
              "          (albert_layers): ModuleList(\n",
              "            (0): AlbertLayer(\n",
              "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (attention): AlbertAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (attention_dropout): Dropout(p=0, inplace=False)\n",
              "                (output_dropout): Dropout(p=0, inplace=False)\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              )\n",
              "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (pooler_activation): Tanh()\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UV6yrQU5xny",
        "outputId": "d6ae8f42-9713-4832-ffbe-39077090ed71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(test_data.message.apply(lambda x: len(x)).quantile([0.9]))\n",
        "MAX_LEN = 155"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9    155.0\n",
            "Name: message, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpflwMZu53zx",
        "outputId": "4c1a1aa6-adea-4926-cebf-1ffa4e1d20a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    41403\n",
              "0    30454\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG_zhFF-jyfr"
      },
      "source": [
        "###Convert Text for FinALBERT model Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-DFc-G656GJ",
        "outputId": "ece91a0b-fa95-44c0-ebe7-edf8be86a01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test examples: {}'.format(len(test_data)))\n",
        "# test_data\n",
        "# Create sentence and label lists\n",
        "test = test_data.message.values\n",
        "labels = test_data.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for text in test:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation = True\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test examples: 71857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bORgKQcmj7s7"
      },
      "source": [
        "###Prediction on test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoQlcYIm6AgX",
        "outputId": "33f0a571-9b17-49f6-c785-f9d110045266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch.nn.functional as F  #for softmax function    \n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "predicted_labels = []\n",
        "prediction = np.empty((0,2)) #empty numpy for appending our output\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
        "      # print(outputs)\n",
        "      pt_predictions = F.softmax(outputs[0], dim=-1)  #applying softmax activation function\n",
        "      # print(pt_predictions)\n",
        "      prediction = np.append(prediction, pt_predictions.detach().cpu().numpy(), axis=0) #appending the prediction\n",
        "      # print(outputs[0][0])\n",
        "      # predicted_labels.append(np.multiply(np.argmax(outputs[0].detach().cpu().numpy()), b_input_mask.detach().cpu().numpy()))\n",
        "  logits = outputs[0]\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "  # f_predicted_labels = np.concatenate(predicted_labels).astype(int)\n",
        "  \n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 71,857 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azQwyB5-j_Uo"
      },
      "source": [
        "###Convert model predictions to labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7xEbrEv79yD",
        "outputId": "1eaf55a1-057c-4503-8493-b55638d0d5a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prediction.shape\n",
        "sub = np.argmax(prediction, axis=1)\n",
        "print(sub)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI7KlKntkDJo"
      },
      "source": [
        "###Add predicted labels to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csV8m43X7_5T",
        "outputId": "1cdd2ee5-326d-4d07-9e44-be59f53318f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data['predicted_labels'] = list(sub)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yYXUMCmBGAb",
        "outputId": "115e3750-3a11-4fdc-f1b5-a8070764ae09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>message</th>\n",
              "      <th>datetime</th>\n",
              "      <th>user</th>\n",
              "      <th>message_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>label</th>\n",
              "      <th>predicted_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2719765</th>\n",
              "      <td>HD</td>\n",
              "      <td>spy careful bulls still asia amp eu need respo...</td>\n",
              "      <td>2020-04-20 18:55:28</td>\n",
              "      <td>543250</td>\n",
              "      <td>207432134</td>\n",
              "      <td>2020-04-20</td>\n",
              "      <td>18:55:28</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4542299</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>tsla 800 today given leggo</td>\n",
              "      <td>2020-04-17 14:55:17</td>\n",
              "      <td>1651138</td>\n",
              "      <td>206977690</td>\n",
              "      <td>2020-04-17</td>\n",
              "      <td>14:55:17</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4852592</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>tsla descending triangle forming</td>\n",
              "      <td>2020-01-10 17:29:31</td>\n",
              "      <td>227500</td>\n",
              "      <td>189908208</td>\n",
              "      <td>2020-01-10</td>\n",
              "      <td>17:29:31</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4647903</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>tsla brokerage houses buying today</td>\n",
              "      <td>2020-03-02 15:16:48</td>\n",
              "      <td>1134428</td>\n",
              "      <td>197676977</td>\n",
              "      <td>2020-03-02</td>\n",
              "      <td>15:16:48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4625249</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>tsla smoke mirrors joke headed south</td>\n",
              "      <td>2020-03-11 16:39:46</td>\n",
              "      <td>1550829</td>\n",
              "      <td>199622789</td>\n",
              "      <td>2020-03-11</td>\n",
              "      <td>16:39:46</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4399117</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>tsla doubt little retail scrubs face tears joy...</td>\n",
              "      <td>2020-07-02 13:02:01</td>\n",
              "      <td>2187451</td>\n",
              "      <td>224867099</td>\n",
              "      <td>2020-07-02</td>\n",
              "      <td>13:02:01</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2840850</th>\n",
              "      <td>NFLX</td>\n",
              "      <td>nflx crossed 20 day moving average macd bullis...</td>\n",
              "      <td>2020-06-09 21:28:19</td>\n",
              "      <td>2843</td>\n",
              "      <td>218526260</td>\n",
              "      <td>2020-06-09</td>\n",
              "      <td>21:28:19</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4522142</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>capr forget tsla play day hands</td>\n",
              "      <td>2020-04-29 17:12:13</td>\n",
              "      <td>2264337</td>\n",
              "      <td>209319820</td>\n",
              "      <td>2020-04-29</td>\n",
              "      <td>17:12:13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3588982</th>\n",
              "      <td>QQQ</td>\n",
              "      <td>spy qq iwm uso blog regular updates free analy...</td>\n",
              "      <td>2020-04-06 18:57:12</td>\n",
              "      <td>440416</td>\n",
              "      <td>204911533</td>\n",
              "      <td>2020-04-06</td>\n",
              "      <td>18:57:12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2123920</th>\n",
              "      <td>DIS</td>\n",
              "      <td>dis going people signing petition stop reopeni...</td>\n",
              "      <td>2020-06-19 01:01:30</td>\n",
              "      <td>3652583</td>\n",
              "      <td>221227234</td>\n",
              "      <td>2020-06-19</td>\n",
              "      <td>01:01:30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71857 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        symbol  ... predicted_labels\n",
              "2719765     HD  ...                1\n",
              "4542299   TSLA  ...                1\n",
              "4852592   TSLA  ...                1\n",
              "4647903   TSLA  ...                1\n",
              "4625249   TSLA  ...                1\n",
              "...        ...  ...              ...\n",
              "4399117   TSLA  ...                1\n",
              "2840850   NFLX  ...                1\n",
              "4522142   TSLA  ...                1\n",
              "3588982    QQQ  ...                1\n",
              "2123920    DIS  ...                1\n",
              "\n",
              "[71857 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDE_xuR-kIxe"
      },
      "source": [
        "###Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRmtNxLtBIbf",
        "outputId": "ed5a224b-36c9-48b7-a6d8-4eccb487eaec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(\"F1 score: {}\".format(precision_recall_fscore_support(flat_predictions, flat_true_labels, average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: (0.5, 0.2880930180775707, 0.36555712519865796, None)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51R2tNSmC6ho",
        "outputId": "3a803b99-a2e6-4ace-f1e9-b57bba53b5a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(flat_true_labels, flat_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     30454\n",
            "           1       0.58      1.00      0.73     41403\n",
            "\n",
            "    accuracy                           0.58     71857\n",
            "   macro avg       0.29      0.50      0.37     71857\n",
            "weighted avg       0.33      0.58      0.42     71857\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O5YELfEDCPo",
        "outputId": "419ffc93-0b6d-4d7d-9796-3c2f7022c486",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy: {}\".format(accuracy_score(flat_predictions, flat_true_labels)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5761860361551414\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}