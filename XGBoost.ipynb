{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "XGBoost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjag7682/CS9-1-NLP-for-Twitter-Data-for-predicting-stocks/blob/master/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2lJCU_IwDqG"
      },
      "source": [
        "## GPU connect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al2_IHd8wF60"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMBtcA_6wNA4"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3KjZMwFXrRy"
      },
      "source": [
        "## Imports and Installs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cy0fYMqXsGm"
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1-1-NxTeGh9HktAvcYMDLuCe0jJK6Cngb'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('Combined_FAANG_percentage_2.2.csv')\n",
        "\n",
        "id = '1-4wGVlhCObAoAM_DOLL3D4YsJhOb1ZSj'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('Combined_FAANG_binary_previous.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMFYNScJqx0k"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xwxC4mHqzvx"
      },
      "source": [
        "!pip install contractions\n",
        "!pip install emoji\n",
        "!pip install ekphrasis\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "import nltk\n",
        "import contractions\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer \n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "import requests \n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import pprint\n",
        "import json\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "from ekphrasis.classes.segmenter import Segmenter\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vMi6m9rX6nb"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARjbN6PUX-Y0"
      },
      "source": [
        "df_comb = pd.read_csv('/content/Combined_FAANG_percentage_2.2.csv', sep=',')\n",
        "df_comb = df_comb[df_comb['message'].notna()]\n",
        "df = df_comb.sample(frac=1) # consider whole data and shuffle it\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjBV-r1LGQMO"
      },
      "source": [
        "Drop before a particular date depending on duration of data considered\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIlhs8quZTXl"
      },
      "source": [
        "df.drop(df[df['Date'] <= '2019-07-20'].index, inplace = True) \n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWdtN6RbZXLY"
      },
      "source": [
        "df[\"label\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjWKTPNoGRhX"
      },
      "source": [
        "Drop neutrals and replace negative label -1 with 0. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1x2jej8YE9j"
      },
      "source": [
        "df.drop(df[df['label'] == 0].index, inplace = True) \n",
        "df[\"label\"].replace({-1: 0}, inplace=True) # therefore, 0 - negative, 1 - positive\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trrlIqbfZc48"
      },
      "source": [
        "df[\"label\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfWd9UgpYPFz"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnYF8e12ZjPR"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUB_w-ryFWbo"
      },
      "source": [
        "## Implement XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaZnTh8CZwVa"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Pipeline to run XGBoost with 2 vectorizations techniques - CountVectorizer and TfIdfTransformer\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', XGBClassifier())])\n",
        "\n",
        "# Paramters to be tested with for CountVectorizer, TfidfTransformer and XGBClassifier\n",
        "tuned_parameters = {\n",
        "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'tfidf__norm': ('l1', 'l2'),\n",
        "    'clf__alpha': [1, 0.1,0.5]\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjHjN9APGU7Y"
      },
      "source": [
        "Train, Predict and print Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVIAS0tNZ8Xa"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "score = 'f1_macro'\n",
        "clf = GridSearchCV(text_clf, tuned_parameters, cv=5, scoring=score)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "# Predict and print classification report\n",
        "print(classification_report(y_test, clf.predict(x_test), digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwBcVVvvGjTz"
      },
      "source": [
        "Display parameters through which model gave best results\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bblk11ibZ9v0"
      },
      "source": [
        "clf.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLIR-LoyGmui"
      },
      "source": [
        "Display estimator that gave the best results\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIyt_a2XZ-9t"
      },
      "source": [
        "clf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74mBhoYPGGZ7"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAx306b7aAcP"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/xgboost.bin', 'wb') as f:\n",
        "\n",
        "    pickle.dump(clf, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}